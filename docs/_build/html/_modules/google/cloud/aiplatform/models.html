


<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>google.cloud.aiplatform.models &mdash; google-cloud-aiplatform  documentation</title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> google-cloud-aiplatform
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../aiplatform.html">Google Cloud Aiplatform SDK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../aiplatform_v1/services.html">Services for Google Cloud Aiplatform v1 API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../aiplatform_v1/types.html">Types for Google Cloud Aiplatform v1 API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../aiplatform_v1beta1/services.html">Services for Google Cloud Aiplatform v1beta1 API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../aiplatform_v1beta1/types.html">Types for Google Cloud Aiplatform v1beta1 API</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../changelog.html">Changelog</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">google-cloud-aiplatform</a>
        
      </nav>


      <div class="wy-nav-content">

        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
      <li>google.cloud.aiplatform.models</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
      <div class="documentwrapper">
          

          <div class="body" role="main">
          	<div class="admonition" id="python2-eol"> 
          	 As of January 1, 2020 this library no longer supports Python 2 on the latest released version. 
          	 Library versions released prior to that date will continue to be available. For more information please
          	 visit <a href="https://cloud.google.com/python/docs/python2-sunset/">Python 2 support on Google Cloud</a>.
          	</div>
            
  <h1>Source code for google.cloud.aiplatform.models</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>

<span class="c1"># Copyright 2020 Google LLC</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1">#</span>
<span class="kn">import</span> <span class="nn">proto</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">NamedTuple</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">from</span> <span class="nn">google.api_core</span> <span class="kn">import</span> <span class="n">operation</span>
<span class="kn">from</span> <span class="nn">google.auth</span> <span class="kn">import</span> <span class="n">credentials</span> <span class="k">as</span> <span class="n">auth_credentials</span>

<span class="kn">from</span> <span class="nn">google.cloud.aiplatform</span> <span class="kn">import</span> <span class="n">base</span>
<span class="kn">from</span> <span class="nn">google.cloud.aiplatform</span> <span class="kn">import</span> <span class="n">compat</span>
<span class="kn">from</span> <span class="nn">google.cloud.aiplatform</span> <span class="kn">import</span> <span class="n">explain</span>
<span class="kn">from</span> <span class="nn">google.cloud.aiplatform</span> <span class="kn">import</span> <span class="n">initializer</span>
<span class="kn">from</span> <span class="nn">google.cloud.aiplatform</span> <span class="kn">import</span> <span class="n">jobs</span>
<span class="kn">from</span> <span class="nn">google.cloud.aiplatform</span> <span class="kn">import</span> <span class="n">models</span>
<span class="kn">from</span> <span class="nn">google.cloud.aiplatform</span> <span class="kn">import</span> <span class="n">utils</span>

<span class="kn">from</span> <span class="nn">google.cloud.aiplatform.compat.services</span> <span class="kn">import</span> <span class="n">endpoint_service_client</span>

<span class="kn">from</span> <span class="nn">google.cloud.aiplatform.compat.types</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">encryption_spec</span> <span class="k">as</span> <span class="n">gca_encryption_spec</span><span class="p">,</span>
    <span class="n">endpoint</span> <span class="k">as</span> <span class="n">gca_endpoint_compat</span><span class="p">,</span>
    <span class="n">endpoint_v1</span> <span class="k">as</span> <span class="n">gca_endpoint_v1</span><span class="p">,</span>
    <span class="n">endpoint_v1beta1</span> <span class="k">as</span> <span class="n">gca_endpoint_v1beta1</span><span class="p">,</span>
    <span class="n">explanation_v1beta1</span> <span class="k">as</span> <span class="n">gca_explanation_v1beta1</span><span class="p">,</span>
    <span class="n">io</span> <span class="k">as</span> <span class="n">gca_io_compat</span><span class="p">,</span>
    <span class="n">machine_resources</span> <span class="k">as</span> <span class="n">gca_machine_resources_compat</span><span class="p">,</span>
    <span class="n">machine_resources_v1beta1</span> <span class="k">as</span> <span class="n">gca_machine_resources_v1beta1</span><span class="p">,</span>
    <span class="n">model</span> <span class="k">as</span> <span class="n">gca_model_compat</span><span class="p">,</span>
    <span class="n">model_service</span> <span class="k">as</span> <span class="n">gca_model_service_compat</span><span class="p">,</span>
    <span class="n">model_v1beta1</span> <span class="k">as</span> <span class="n">gca_model_v1beta1</span><span class="p">,</span>
    <span class="n">env_var</span> <span class="k">as</span> <span class="n">gca_env_var_compat</span><span class="p">,</span>
    <span class="n">env_var_v1beta1</span> <span class="k">as</span> <span class="n">gca_env_var_v1beta1</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">google.protobuf</span> <span class="kn">import</span> <span class="n">json_format</span>


<span class="n">_LOGGER</span> <span class="o">=</span> <span class="n">base</span><span class="o">.</span><span class="n">Logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Prediction</span><span class="p">(</span><span class="n">NamedTuple</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Prediction class envelopes returned Model predictions and the Model id.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        predictions:</span>
<span class="sd">            The predictions that are the output of the predictions</span>
<span class="sd">            call. The schema of any single prediction may be specified via</span>
<span class="sd">            Endpoint&#39;s DeployedModels&#39; [Model&#39;s][google.cloud.aiplatform.v1beta1.DeployedModel.model]</span>
<span class="sd">            [PredictSchemata&#39;s][google.cloud.aiplatform.v1beta1.Model.predict_schemata]</span>
<span class="sd">        deployed_model_id:</span>
<span class="sd">            ID of the Endpoint&#39;s DeployedModel that served this prediction.</span>
<span class="sd">        explanations:</span>
<span class="sd">            The explanations of the Model&#39;s predictions. It has the same number</span>
<span class="sd">            of elements as instances to be explained. Default is None.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">predictions</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">]</span>
    <span class="n">deployed_model_id</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">explanations</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">gca_explanation_v1beta1</span><span class="o">.</span><span class="n">Explanation</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>


<div class="viewcode-block" id="Endpoint"><a class="viewcode-back" href="../../../../aiplatform.html#google.cloud.aiplatform.Endpoint">[docs]</a><span class="k">class</span> <span class="nc">Endpoint</span><span class="p">(</span><span class="n">base</span><span class="o">.</span><span class="n">VertexAiResourceNounWithFutureManager</span><span class="p">):</span>

    <span class="n">client_class</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">EndpointClientWithOverride</span>
    <span class="n">_is_client_prediction_client</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">_resource_noun</span> <span class="o">=</span> <span class="s2">&quot;endpoints&quot;</span>
    <span class="n">_getter_method</span> <span class="o">=</span> <span class="s2">&quot;get_endpoint&quot;</span>
    <span class="n">_list_method</span> <span class="o">=</span> <span class="s2">&quot;list_endpoints&quot;</span>
    <span class="n">_delete_method</span> <span class="o">=</span> <span class="s2">&quot;delete_endpoint&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">endpoint_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">project</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">location</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">credentials</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">auth_credentials</span><span class="o">.</span><span class="n">Credentials</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieves an endpoint resource.</span>

<span class="sd">        Args:</span>
<span class="sd">            endpoint_name (str):</span>
<span class="sd">                Required. A fully-qualified endpoint resource name or endpoint ID.</span>
<span class="sd">                Example: &quot;projects/123/locations/us-central1/endpoints/456&quot; or</span>
<span class="sd">                &quot;456&quot; when project and location are initialized or passed.</span>
<span class="sd">            project (str):</span>
<span class="sd">                Optional. Project to retrieve endpoint from. If not set, project</span>
<span class="sd">                set in aiplatform.init will be used.</span>
<span class="sd">            location (str):</span>
<span class="sd">                Optional. Location to retrieve endpoint from. If not set, location</span>
<span class="sd">                set in aiplatform.init will be used.</span>
<span class="sd">            credentials (auth_credentials.Credentials):</span>
<span class="sd">                Optional. Custom credentials to use to upload this model. Overrides</span>
<span class="sd">                credentials set in aiplatform.init.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span>
            <span class="n">location</span><span class="o">=</span><span class="n">location</span><span class="p">,</span>
            <span class="n">credentials</span><span class="o">=</span><span class="n">credentials</span><span class="p">,</span>
            <span class="n">resource_name</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_gca_resource</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_gca_resource</span><span class="p">(</span><span class="n">resource_name</span><span class="o">=</span><span class="n">endpoint_name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_prediction_client</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_instantiate_prediction_client</span><span class="p">(</span>
            <span class="n">location</span><span class="o">=</span><span class="n">location</span> <span class="ow">or</span> <span class="n">initializer</span><span class="o">.</span><span class="n">global_config</span><span class="o">.</span><span class="n">location</span><span class="p">,</span>
            <span class="n">credentials</span><span class="o">=</span><span class="n">credentials</span><span class="p">,</span>
        <span class="p">)</span>

<div class="viewcode-block" id="Endpoint.create"><a class="viewcode-back" href="../../../../aiplatform.html#google.cloud.aiplatform.Endpoint.create">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">create</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">display_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">description</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">(),</span>
        <span class="n">project</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">location</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">credentials</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">auth_credentials</span><span class="o">.</span><span class="n">Credentials</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">encryption_spec_key_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sync</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Endpoint&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Creates a new endpoint.</span>

<span class="sd">        Args:</span>
<span class="sd">            display_name (str):</span>
<span class="sd">                Required. The user-defined name of the Endpoint.</span>
<span class="sd">                The name can be up to 128 characters long and can be consist</span>
<span class="sd">                of any UTF-8 characters.</span>
<span class="sd">            project (str):</span>
<span class="sd">                Required. Project to retrieve endpoint from. If not set, project</span>
<span class="sd">                set in aiplatform.init will be used.</span>
<span class="sd">            location (str):</span>
<span class="sd">                Required. Location to retrieve endpoint from. If not set, location</span>
<span class="sd">                set in aiplatform.init will be used.</span>
<span class="sd">            description (str):</span>
<span class="sd">                Optional. The description of the Endpoint.</span>
<span class="sd">            labels (Dict):</span>
<span class="sd">                Optional. The labels with user-defined metadata to</span>
<span class="sd">                organize your Endpoints.</span>
<span class="sd">                Label keys and values can be no longer than 64</span>
<span class="sd">                characters (Unicode codepoints), can only</span>
<span class="sd">                contain lowercase letters, numeric characters,</span>
<span class="sd">                underscores and dashes. International characters</span>
<span class="sd">                are allowed.</span>
<span class="sd">                See https://goo.gl/xmQnxf for more information</span>
<span class="sd">                and examples of labels.</span>
<span class="sd">            metadata (Sequence[Tuple[str, str]]):</span>
<span class="sd">                Optional. Strings which should be sent along with the request as</span>
<span class="sd">                metadata.</span>
<span class="sd">            credentials (auth_credentials.Credentials):</span>
<span class="sd">                Optional. Custom credentials to use to upload this model. Overrides</span>
<span class="sd">                credentials set in aiplatform.init.</span>
<span class="sd">            encryption_spec_key_name (Optional[str]):</span>
<span class="sd">                Optional. The Cloud KMS resource identifier of the customer</span>
<span class="sd">                managed encryption key used to protect the model. Has the</span>
<span class="sd">                form:</span>
<span class="sd">                ``projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key``.</span>
<span class="sd">                The key needs to be in the same region as where the compute</span>
<span class="sd">                resource is created.</span>

<span class="sd">                If set, this Endpoint and all sub-resources of this Endpoint will be secured by this key.</span>

<span class="sd">                Overrides encryption_spec_key_name set in aiplatform.init.</span>
<span class="sd">            sync (bool):</span>
<span class="sd">                Whether to execute this method synchronously. If False, this method</span>
<span class="sd">                will be executed in concurrent Future and any downstream object will</span>
<span class="sd">                be immediately returned and synced when the Future has completed.</span>
<span class="sd">        Returns:</span>
<span class="sd">            endpoint (endpoint.Endpoint):</span>
<span class="sd">                Created endpoint.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">api_client</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_instantiate_client</span><span class="p">(</span><span class="n">location</span><span class="o">=</span><span class="n">location</span><span class="p">,</span> <span class="n">credentials</span><span class="o">=</span><span class="n">credentials</span><span class="p">)</span>

        <span class="n">utils</span><span class="o">.</span><span class="n">validate_display_name</span><span class="p">(</span><span class="n">display_name</span><span class="p">)</span>

        <span class="n">project</span> <span class="o">=</span> <span class="n">project</span> <span class="ow">or</span> <span class="n">initializer</span><span class="o">.</span><span class="n">global_config</span><span class="o">.</span><span class="n">project</span>
        <span class="n">location</span> <span class="o">=</span> <span class="n">location</span> <span class="ow">or</span> <span class="n">initializer</span><span class="o">.</span><span class="n">global_config</span><span class="o">.</span><span class="n">location</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_create</span><span class="p">(</span>
            <span class="n">api_client</span><span class="o">=</span><span class="n">api_client</span><span class="p">,</span>
            <span class="n">display_name</span><span class="o">=</span><span class="n">display_name</span><span class="p">,</span>
            <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span>
            <span class="n">location</span><span class="o">=</span><span class="n">location</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="n">description</span><span class="p">,</span>
            <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
            <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
            <span class="n">credentials</span><span class="o">=</span><span class="n">credentials</span><span class="p">,</span>
            <span class="n">encryption_spec</span><span class="o">=</span><span class="n">initializer</span><span class="o">.</span><span class="n">global_config</span><span class="o">.</span><span class="n">get_encryption_spec</span><span class="p">(</span>
                <span class="n">encryption_spec_key_name</span><span class="o">=</span><span class="n">encryption_spec_key_name</span>
            <span class="p">),</span>
            <span class="n">sync</span><span class="o">=</span><span class="n">sync</span><span class="p">,</span>
        <span class="p">)</span></div>

    <span class="nd">@classmethod</span>
    <span class="nd">@base</span><span class="o">.</span><span class="n">optional_sync</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">_create</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">api_client</span><span class="p">:</span> <span class="n">endpoint_service_client</span><span class="o">.</span><span class="n">EndpointServiceClient</span><span class="p">,</span>
        <span class="n">display_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">project</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">location</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">description</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">(),</span>
        <span class="n">credentials</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">auth_credentials</span><span class="o">.</span><span class="n">Credentials</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">encryption_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">gca_encryption_spec</span><span class="o">.</span><span class="n">EncryptionSpec</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sync</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Endpoint&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Creates a new endpoint by calling the API client.</span>

<span class="sd">        Args:</span>
<span class="sd">            api_client (EndpointServiceClient):</span>
<span class="sd">                Required. An instance of EndpointServiceClient with the correct</span>
<span class="sd">                api_endpoint already set based on user&#39;s preferences.</span>
<span class="sd">            display_name (str):</span>
<span class="sd">                Required. The user-defined name of the Endpoint.</span>
<span class="sd">                The name can be up to 128 characters long and can be consist</span>
<span class="sd">                of any UTF-8 characters.</span>
<span class="sd">            project (str):</span>
<span class="sd">                Required. Project to retrieve endpoint from. If not set, project</span>
<span class="sd">                set in aiplatform.init will be used.</span>
<span class="sd">            location (str):</span>
<span class="sd">                Required. Location to retrieve endpoint from. If not set, location</span>
<span class="sd">                set in aiplatform.init will be used.</span>
<span class="sd">            description (str):</span>
<span class="sd">                Optional. The description of the Endpoint.</span>
<span class="sd">            labels (Dict):</span>
<span class="sd">                Optional. The labels with user-defined metadata to</span>
<span class="sd">                organize your Endpoints.</span>
<span class="sd">                Label keys and values can be no longer than 64</span>
<span class="sd">                characters (Unicode codepoints), can only</span>
<span class="sd">                contain lowercase letters, numeric characters,</span>
<span class="sd">                underscores and dashes. International characters</span>
<span class="sd">                are allowed.</span>
<span class="sd">                See https://goo.gl/xmQnxf for more information</span>
<span class="sd">                and examples of labels.</span>
<span class="sd">            metadata (Sequence[Tuple[str, str]]):</span>
<span class="sd">                Optional. Strings which should be sent along with the request as</span>
<span class="sd">                metadata.</span>
<span class="sd">            credentials (auth_credentials.Credentials):</span>
<span class="sd">                Optional. Custom credentials to use to upload this model. Overrides</span>
<span class="sd">                credentials set in aiplatform.init.</span>
<span class="sd">            encryption_spec (Optional[gca_encryption_spec.EncryptionSpec]):</span>
<span class="sd">                Optional. The Cloud KMS customer managed encryption key used to protect the dataset.</span>
<span class="sd">                The key needs to be in the same region as where the compute</span>
<span class="sd">                resource is created.</span>

<span class="sd">                If set, this Dataset and all sub-resources of this Dataset will be secured by this key.</span>
<span class="sd">            sync (bool):</span>
<span class="sd">                Whether to create this endpoint synchronously.</span>
<span class="sd">        Returns:</span>
<span class="sd">            endpoint (endpoint.Endpoint):</span>
<span class="sd">                Created endpoint.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">parent</span> <span class="o">=</span> <span class="n">initializer</span><span class="o">.</span><span class="n">global_config</span><span class="o">.</span><span class="n">common_location_path</span><span class="p">(</span>
            <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span> <span class="n">location</span><span class="o">=</span><span class="n">location</span>
        <span class="p">)</span>

        <span class="n">gapic_endpoint</span> <span class="o">=</span> <span class="n">gca_endpoint_compat</span><span class="o">.</span><span class="n">Endpoint</span><span class="p">(</span>
            <span class="n">display_name</span><span class="o">=</span><span class="n">display_name</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="n">description</span><span class="p">,</span>
            <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
            <span class="n">encryption_spec</span><span class="o">=</span><span class="n">encryption_spec</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">operation_future</span> <span class="o">=</span> <span class="n">api_client</span><span class="o">.</span><span class="n">create_endpoint</span><span class="p">(</span>
            <span class="n">parent</span><span class="o">=</span><span class="n">parent</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="n">gapic_endpoint</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span>
        <span class="p">)</span>

        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">log_create_with_lro</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">operation_future</span><span class="p">)</span>

        <span class="n">created_endpoint</span> <span class="o">=</span> <span class="n">operation_future</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>

        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">log_create_complete</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">created_endpoint</span><span class="p">,</span> <span class="s2">&quot;endpoint&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">endpoint_name</span><span class="o">=</span><span class="n">created_endpoint</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span>
            <span class="n">location</span><span class="o">=</span><span class="n">location</span><span class="p">,</span>
            <span class="n">credentials</span><span class="o">=</span><span class="n">credentials</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_allocate_traffic</span><span class="p">(</span>
        <span class="n">traffic_split</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">traffic_percentage</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Allocates desired traffic to new deployed model and scales traffic</span>
<span class="sd">        of older deployed models.</span>

<span class="sd">        Args:</span>
<span class="sd">            traffic_split (Dict[str, int]):</span>
<span class="sd">                Required. Current traffic split of deployed models in endpoint.</span>
<span class="sd">            traffic_percentage (int):</span>
<span class="sd">                Required. Desired traffic to new deployed model.</span>
<span class="sd">        Returns:</span>
<span class="sd">            new_traffic_split (Dict[str, int]):</span>
<span class="sd">                Traffic split to use.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_traffic_split</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">old_models_traffic</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">-</span> <span class="n">traffic_percentage</span>
        <span class="k">if</span> <span class="n">old_models_traffic</span><span class="p">:</span>
            <span class="n">unallocated_traffic</span> <span class="o">=</span> <span class="n">old_models_traffic</span>
            <span class="k">for</span> <span class="n">deployed_model</span> <span class="ow">in</span> <span class="n">traffic_split</span><span class="p">:</span>
                <span class="n">current_traffic</span> <span class="o">=</span> <span class="n">traffic_split</span><span class="p">[</span><span class="n">deployed_model</span><span class="p">]</span>
                <span class="n">new_traffic</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">current_traffic</span> <span class="o">/</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">old_models_traffic</span><span class="p">)</span>
                <span class="n">new_traffic_split</span><span class="p">[</span><span class="n">deployed_model</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_traffic</span>
                <span class="n">unallocated_traffic</span> <span class="o">-=</span> <span class="n">new_traffic</span>
            <span class="c1"># will likely under-allocate. make total 100.</span>
            <span class="k">for</span> <span class="n">deployed_model</span> <span class="ow">in</span> <span class="n">new_traffic_split</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">unallocated_traffic</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">break</span>
                <span class="n">new_traffic_split</span><span class="p">[</span><span class="n">deployed_model</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">unallocated_traffic</span> <span class="o">-=</span> <span class="mi">1</span>

        <span class="n">new_traffic_split</span><span class="p">[</span><span class="s2">&quot;0&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">traffic_percentage</span>

        <span class="k">return</span> <span class="n">new_traffic_split</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_unallocate_traffic</span><span class="p">(</span>
        <span class="n">traffic_split</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">deployed_model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Sets deployed model id&#39;s traffic to 0 and scales the traffic of</span>
<span class="sd">        other deployed models.</span>

<span class="sd">        Args:</span>
<span class="sd">            traffic_split (Dict[str, int]):</span>
<span class="sd">                Required. Current traffic split of deployed models in endpoint.</span>
<span class="sd">            deployed_model_id (str):</span>
<span class="sd">                Required. Desired traffic to new deployed model.</span>
<span class="sd">        Returns:</span>
<span class="sd">            new_traffic_split (Dict[str, int]):</span>
<span class="sd">                Traffic split to use.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_traffic_split</span> <span class="o">=</span> <span class="n">traffic_split</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">del</span> <span class="n">new_traffic_split</span><span class="p">[</span><span class="n">deployed_model_id</span><span class="p">]</span>
        <span class="n">deployed_model_id_traffic</span> <span class="o">=</span> <span class="n">traffic_split</span><span class="p">[</span><span class="n">deployed_model_id</span><span class="p">]</span>
        <span class="n">traffic_percent_left</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">-</span> <span class="n">deployed_model_id_traffic</span>

        <span class="k">if</span> <span class="n">traffic_percent_left</span><span class="p">:</span>
            <span class="n">unallocated_traffic</span> <span class="o">=</span> <span class="mi">100</span>
            <span class="k">for</span> <span class="n">deployed_model</span> <span class="ow">in</span> <span class="n">new_traffic_split</span><span class="p">:</span>
                <span class="n">current_traffic</span> <span class="o">=</span> <span class="n">traffic_split</span><span class="p">[</span><span class="n">deployed_model</span><span class="p">]</span>
                <span class="n">new_traffic</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">current_traffic</span> <span class="o">/</span> <span class="n">traffic_percent_left</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
                <span class="n">new_traffic_split</span><span class="p">[</span><span class="n">deployed_model</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_traffic</span>
                <span class="n">unallocated_traffic</span> <span class="o">-=</span> <span class="n">new_traffic</span>
            <span class="c1"># will likely under-allocate. make total 100.</span>
            <span class="k">for</span> <span class="n">deployed_model</span> <span class="ow">in</span> <span class="n">new_traffic_split</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">unallocated_traffic</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">break</span>
                <span class="n">new_traffic_split</span><span class="p">[</span><span class="n">deployed_model</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">unallocated_traffic</span> <span class="o">-=</span> <span class="mi">1</span>

        <span class="n">new_traffic_split</span><span class="p">[</span><span class="n">deployed_model_id</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">return</span> <span class="n">new_traffic_split</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_validate_deploy_args</span><span class="p">(</span>
        <span class="n">min_replica_count</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">max_replica_count</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">accelerator_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">deployed_model_display_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">traffic_split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]],</span>
        <span class="n">traffic_percentage</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">explanation_metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">explain</span><span class="o">.</span><span class="n">ExplanationMetadata</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">explanation_parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">explain</span><span class="o">.</span><span class="n">ExplanationParameters</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Helper method to validate deploy arguments.</span>

<span class="sd">        Args:</span>
<span class="sd">            min_replica_count (int):</span>
<span class="sd">                Required. The minimum number of machine replicas this deployed</span>
<span class="sd">                model will be always deployed on. If traffic against it increases,</span>
<span class="sd">                it may dynamically be deployed onto more replicas, and as traffic</span>
<span class="sd">                decreases, some of these extra replicas may be freed.</span>
<span class="sd">            max_replica_count (int):</span>
<span class="sd">                Required. The maximum number of replicas this deployed model may</span>
<span class="sd">                be deployed on when the traffic against it increases. If requested</span>
<span class="sd">                value is too large, the deployment will error, but if deployment</span>
<span class="sd">                succeeds then the ability to scale the model to that many replicas</span>
<span class="sd">                is guaranteed (barring service outages). If traffic against the</span>
<span class="sd">                deployed model increases beyond what its replicas at maximum may</span>
<span class="sd">                handle, a portion of the traffic will be dropped. If this value</span>
<span class="sd">                is not provided, the larger value of min_replica_count or 1 will</span>
<span class="sd">                be used. If value provided is smaller than min_replica_count, it</span>
<span class="sd">                will automatically be increased to be min_replica_count.</span>
<span class="sd">            accelerator_type (str):</span>
<span class="sd">                Required. Hardware accelerator type. One of ACCELERATOR_TYPE_UNSPECIFIED,</span>
<span class="sd">                NVIDIA_TESLA_K80, NVIDIA_TESLA_P100, NVIDIA_TESLA_V100, NVIDIA_TESLA_P4,</span>
<span class="sd">                NVIDIA_TESLA_T4</span>
<span class="sd">            deployed_model_display_name (str):</span>
<span class="sd">                Required. The display name of the DeployedModel. If not provided</span>
<span class="sd">                upon creation, the Model&#39;s display_name is used.</span>
<span class="sd">            traffic_split (Dict[str, int]):</span>
<span class="sd">                Required. A map from a DeployedModel&#39;s ID to the percentage of</span>
<span class="sd">                this Endpoint&#39;s traffic that should be forwarded to that DeployedModel.</span>
<span class="sd">                If a DeployedModel&#39;s ID is not listed in this map, then it receives</span>
<span class="sd">                no traffic. The traffic percentage values must add up to 100, or</span>
<span class="sd">                map must be empty if the Endpoint is to not accept any traffic at</span>
<span class="sd">                the moment. Key for model being deployed is &quot;0&quot;. Should not be</span>
<span class="sd">                provided if traffic_percentage is provided.</span>
<span class="sd">            traffic_percentage (int):</span>
<span class="sd">                Required. Desired traffic to newly deployed model. Defaults to</span>
<span class="sd">                0 if there are pre-existing deployed models. Defaults to 100 if</span>
<span class="sd">                there are no pre-existing deployed models. Negative values should</span>
<span class="sd">                not be provided. Traffic of previously deployed models at the endpoint</span>
<span class="sd">                will be scaled down to accommodate new deployed model&#39;s traffic.</span>
<span class="sd">                Should not be provided if traffic_split is provided.</span>
<span class="sd">            explanation_metadata (explain.ExplanationMetadata):</span>
<span class="sd">                Optional. Metadata describing the Model&#39;s input and output for explanation.</span>
<span class="sd">                Both `explanation_metadata` and `explanation_parameters` must be</span>
<span class="sd">                passed together when used. For more details, see</span>
<span class="sd">                `Ref docs &lt;http://tinyurl.com/1igh60kt&gt;`</span>
<span class="sd">            explanation_parameters (explain.ExplanationParameters):</span>
<span class="sd">                Optional. Parameters to configure explaining for Model&#39;s predictions.</span>
<span class="sd">                For more details, see `Ref docs &lt;http://tinyurl.com/1an4zake&gt;`</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: if Min or Max replica is negative. Traffic percentage &gt; 100 or</span>
<span class="sd">                &lt; 0. Or if traffic_split does not sum to 100.</span>

<span class="sd">            ValueError: if either explanation_metadata or explanation_parameters</span>
<span class="sd">                but not both are specified.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">min_replica_count</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Min replica cannot be negative.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">max_replica_count</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Max replica cannot be negative.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">deployed_model_display_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">validate_display_name</span><span class="p">(</span><span class="n">deployed_model_display_name</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">traffic_split</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">traffic_percentage</span> <span class="o">&gt;</span> <span class="mi">100</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Traffic percentage cannot be greater than 100.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">traffic_percentage</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Traffic percentage cannot be negative.&quot;</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">traffic_split</span><span class="p">:</span>
            <span class="c1"># TODO(b/172678233) verify every referenced deployed model exists</span>
            <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">traffic_split</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="o">!=</span> <span class="mi">100</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Sum of all traffic within traffic split needs to be 100.&quot;</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="nb">bool</span><span class="p">(</span><span class="n">explanation_metadata</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">explanation_parameters</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Both `explanation_metadata` and `explanation_parameters` should be specified or None.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Raises ValueError if invalid accelerator</span>
        <span class="k">if</span> <span class="n">accelerator_type</span><span class="p">:</span>
            <span class="n">utils</span><span class="o">.</span><span class="n">validate_accelerator_type</span><span class="p">(</span><span class="n">accelerator_type</span><span class="p">)</span>

<div class="viewcode-block" id="Endpoint.deploy"><a class="viewcode-back" href="../../../../aiplatform.html#google.cloud.aiplatform.Endpoint.deploy">[docs]</a>    <span class="k">def</span> <span class="nf">deploy</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="s2">&quot;Model&quot;</span><span class="p">,</span>
        <span class="n">deployed_model_display_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">traffic_percentage</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">traffic_split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">machine_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">min_replica_count</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">max_replica_count</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">accelerator_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">accelerator_count</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">service_account</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">explanation_metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">explain</span><span class="o">.</span><span class="n">ExplanationMetadata</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">explanation_parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">explain</span><span class="o">.</span><span class="n">ExplanationParameters</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">(),</span>
        <span class="n">sync</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Deploys a Model to the Endpoint.</span>

<span class="sd">        Args:</span>
<span class="sd">            model (aiplatform.Model):</span>
<span class="sd">                Required. Model to be deployed.</span>
<span class="sd">            deployed_model_display_name (str):</span>
<span class="sd">                Optional. The display name of the DeployedModel. If not provided</span>
<span class="sd">                upon creation, the Model&#39;s display_name is used.</span>
<span class="sd">            traffic_percentage (int):</span>
<span class="sd">                Optional. Desired traffic to newly deployed model. Defaults to</span>
<span class="sd">                0 if there are pre-existing deployed models. Defaults to 100 if</span>
<span class="sd">                there are no pre-existing deployed models. Negative values should</span>
<span class="sd">                not be provided. Traffic of previously deployed models at the endpoint</span>
<span class="sd">                will be scaled down to accommodate new deployed model&#39;s traffic.</span>
<span class="sd">                Should not be provided if traffic_split is provided.</span>
<span class="sd">            traffic_split (Dict[str, int]):</span>
<span class="sd">                Optional. A map from a DeployedModel&#39;s ID to the percentage of</span>
<span class="sd">                this Endpoint&#39;s traffic that should be forwarded to that DeployedModel.</span>
<span class="sd">                If a DeployedModel&#39;s ID is not listed in this map, then it receives</span>
<span class="sd">                no traffic. The traffic percentage values must add up to 100, or</span>
<span class="sd">                map must be empty if the Endpoint is to not accept any traffic at</span>
<span class="sd">                the moment. Key for model being deployed is &quot;0&quot;. Should not be</span>
<span class="sd">                provided if traffic_percentage is provided.</span>
<span class="sd">            machine_type (str):</span>
<span class="sd">                Optional. The type of machine. Not specifying machine type will</span>
<span class="sd">                result in model to be deployed with automatic resources.</span>
<span class="sd">            min_replica_count (int):</span>
<span class="sd">                Optional. The minimum number of machine replicas this deployed</span>
<span class="sd">                model will be always deployed on. If traffic against it increases,</span>
<span class="sd">                it may dynamically be deployed onto more replicas, and as traffic</span>
<span class="sd">                decreases, some of these extra replicas may be freed.</span>
<span class="sd">            max_replica_count (int):</span>
<span class="sd">                Optional. The maximum number of replicas this deployed model may</span>
<span class="sd">                be deployed on when the traffic against it increases. If requested</span>
<span class="sd">                value is too large, the deployment will error, but if deployment</span>
<span class="sd">                succeeds then the ability to scale the model to that many replicas</span>
<span class="sd">                is guaranteed (barring service outages). If traffic against the</span>
<span class="sd">                deployed model increases beyond what its replicas at maximum may</span>
<span class="sd">                handle, a portion of the traffic will be dropped. If this value</span>
<span class="sd">                is not provided, the larger value of min_replica_count or 1 will</span>
<span class="sd">                be used. If value provided is smaller than min_replica_count, it</span>
<span class="sd">                will automatically be increased to be min_replica_count.</span>
<span class="sd">            accelerator_type (str):</span>
<span class="sd">                Optional. Hardware accelerator type. Must also set accelerator_count if used.</span>
<span class="sd">                One of ACCELERATOR_TYPE_UNSPECIFIED, NVIDIA_TESLA_K80, NVIDIA_TESLA_P100,</span>
<span class="sd">                NVIDIA_TESLA_V100, NVIDIA_TESLA_P4, NVIDIA_TESLA_T4</span>
<span class="sd">            accelerator_count (int):</span>
<span class="sd">                Optional. The number of accelerators to attach to a worker replica.</span>
<span class="sd">            service_account (str):</span>
<span class="sd">                The service account that the DeployedModel&#39;s container runs as. Specify the</span>
<span class="sd">                email address of the service account. If this service account is not</span>
<span class="sd">                specified, the container runs as a service account that doesn&#39;t have access</span>
<span class="sd">                to the resource project.</span>
<span class="sd">                Users deploying the Model must have the `iam.serviceAccounts.actAs`</span>
<span class="sd">                permission on this service account.</span>
<span class="sd">            explanation_metadata (explain.ExplanationMetadata):</span>
<span class="sd">                Optional. Metadata describing the Model&#39;s input and output for explanation.</span>
<span class="sd">                Both `explanation_metadata` and `explanation_parameters` must be</span>
<span class="sd">                passed together when used. For more details, see</span>
<span class="sd">                `Ref docs &lt;http://tinyurl.com/1igh60kt&gt;`</span>
<span class="sd">            explanation_parameters (explain.ExplanationParameters):</span>
<span class="sd">                Optional. Parameters to configure explaining for Model&#39;s predictions.</span>
<span class="sd">                For more details, see `Ref docs &lt;http://tinyurl.com/1an4zake&gt;`</span>
<span class="sd">            metadata (Sequence[Tuple[str, str]]):</span>
<span class="sd">                Optional. Strings which should be sent along with the request as</span>
<span class="sd">                metadata.</span>
<span class="sd">            sync (bool):</span>
<span class="sd">                Whether to execute this method synchronously. If False, this method</span>
<span class="sd">                will be executed in concurrent Future and any downstream object will</span>
<span class="sd">                be immediately returned and synced when the Future has completed.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_deploy_args</span><span class="p">(</span>
            <span class="n">min_replica_count</span><span class="p">,</span>
            <span class="n">max_replica_count</span><span class="p">,</span>
            <span class="n">accelerator_type</span><span class="p">,</span>
            <span class="n">deployed_model_display_name</span><span class="p">,</span>
            <span class="n">traffic_split</span><span class="p">,</span>
            <span class="n">traffic_percentage</span><span class="p">,</span>
            <span class="n">explanation_metadata</span><span class="p">,</span>
            <span class="n">explanation_parameters</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_deploy</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">deployed_model_display_name</span><span class="o">=</span><span class="n">deployed_model_display_name</span><span class="p">,</span>
            <span class="n">traffic_percentage</span><span class="o">=</span><span class="n">traffic_percentage</span><span class="p">,</span>
            <span class="n">traffic_split</span><span class="o">=</span><span class="n">traffic_split</span><span class="p">,</span>
            <span class="n">machine_type</span><span class="o">=</span><span class="n">machine_type</span><span class="p">,</span>
            <span class="n">min_replica_count</span><span class="o">=</span><span class="n">min_replica_count</span><span class="p">,</span>
            <span class="n">max_replica_count</span><span class="o">=</span><span class="n">max_replica_count</span><span class="p">,</span>
            <span class="n">accelerator_type</span><span class="o">=</span><span class="n">accelerator_type</span><span class="p">,</span>
            <span class="n">accelerator_count</span><span class="o">=</span><span class="n">accelerator_count</span><span class="p">,</span>
            <span class="n">service_account</span><span class="o">=</span><span class="n">service_account</span><span class="p">,</span>
            <span class="n">explanation_metadata</span><span class="o">=</span><span class="n">explanation_metadata</span><span class="p">,</span>
            <span class="n">explanation_parameters</span><span class="o">=</span><span class="n">explanation_parameters</span><span class="p">,</span>
            <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
            <span class="n">sync</span><span class="o">=</span><span class="n">sync</span><span class="p">,</span>
        <span class="p">)</span></div>

    <span class="nd">@base</span><span class="o">.</span><span class="n">optional_sync</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">_deploy</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="s2">&quot;Model&quot;</span><span class="p">,</span>
        <span class="n">deployed_model_display_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">traffic_percentage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">traffic_split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">machine_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">min_replica_count</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">max_replica_count</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">accelerator_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">accelerator_count</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">service_account</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">explanation_metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">explain</span><span class="o">.</span><span class="n">ExplanationMetadata</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">explanation_parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">explain</span><span class="o">.</span><span class="n">ExplanationParameters</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">(),</span>
        <span class="n">sync</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Deploys a Model to the Endpoint.</span>

<span class="sd">        Args:</span>
<span class="sd">            model (aiplatform.Model):</span>
<span class="sd">                Required. Model to be deployed.</span>
<span class="sd">            deployed_model_display_name (str):</span>
<span class="sd">                Optional. The display name of the DeployedModel. If not provided</span>
<span class="sd">                upon creation, the Model&#39;s display_name is used.</span>
<span class="sd">            traffic_percentage (int):</span>
<span class="sd">                Optional. Desired traffic to newly deployed model. Defaults to</span>
<span class="sd">                0 if there are pre-existing deployed models. Defaults to 100 if</span>
<span class="sd">                there are no pre-existing deployed models. Negative values should</span>
<span class="sd">                not be provided. Traffic of previously deployed models at the endpoint</span>
<span class="sd">                will be scaled down to accommodate new deployed model&#39;s traffic.</span>
<span class="sd">                Should not be provided if traffic_split is provided.</span>
<span class="sd">            traffic_split (Dict[str, int]):</span>
<span class="sd">                Optional. A map from a DeployedModel&#39;s ID to the percentage of</span>
<span class="sd">                this Endpoint&#39;s traffic that should be forwarded to that DeployedModel.</span>
<span class="sd">                If a DeployedModel&#39;s ID is not listed in this map, then it receives</span>
<span class="sd">                no traffic. The traffic percentage values must add up to 100, or</span>
<span class="sd">                map must be empty if the Endpoint is to not accept any traffic at</span>
<span class="sd">                the moment. Key for model being deployed is &quot;0&quot;. Should not be</span>
<span class="sd">                provided if traffic_percentage is provided.</span>
<span class="sd">            machine_type (str):</span>
<span class="sd">                Optional. The type of machine. Not specifying machine type will</span>
<span class="sd">                result in model to be deployed with automatic resources.</span>
<span class="sd">            min_replica_count (int):</span>
<span class="sd">                Optional. The minimum number of machine replicas this deployed</span>
<span class="sd">                model will be always deployed on. If traffic against it increases,</span>
<span class="sd">                it may dynamically be deployed onto more replicas, and as traffic</span>
<span class="sd">                decreases, some of these extra replicas may be freed.</span>
<span class="sd">            max_replica_count (int):</span>
<span class="sd">                Optional. The maximum number of replicas this deployed model may</span>
<span class="sd">                be deployed on when the traffic against it increases. If requested</span>
<span class="sd">                value is too large, the deployment will error, but if deployment</span>
<span class="sd">                succeeds then the ability to scale the model to that many replicas</span>
<span class="sd">                is guaranteed (barring service outages). If traffic against the</span>
<span class="sd">                deployed model increases beyond what its replicas at maximum may</span>
<span class="sd">                handle, a portion of the traffic will be dropped. If this value</span>
<span class="sd">                is not provided, the larger value of min_replica_count or 1 will</span>
<span class="sd">                be used. If value provided is smaller than min_replica_count, it</span>
<span class="sd">                will automatically be increased to be min_replica_count.</span>
<span class="sd">            accelerator_type (str):</span>
<span class="sd">                Optional. Hardware accelerator type. Must also set accelerator_count if used.</span>
<span class="sd">                One of ACCELERATOR_TYPE_UNSPECIFIED, NVIDIA_TESLA_K80, NVIDIA_TESLA_P100,</span>
<span class="sd">                NVIDIA_TESLA_V100, NVIDIA_TESLA_P4, NVIDIA_TESLA_T4</span>
<span class="sd">            accelerator_count (int):</span>
<span class="sd">                Optional. The number of accelerators to attach to a worker replica.</span>
<span class="sd">            service_account (str):</span>
<span class="sd">                The service account that the DeployedModel&#39;s container runs as. Specify the</span>
<span class="sd">                email address of the service account. If this service account is not</span>
<span class="sd">                specified, the container runs as a service account that doesn&#39;t have access</span>
<span class="sd">                to the resource project.</span>
<span class="sd">                Users deploying the Model must have the `iam.serviceAccounts.actAs`</span>
<span class="sd">                permission on this service account.</span>
<span class="sd">            explanation_metadata (explain.ExplanationMetadata):</span>
<span class="sd">                Optional. Metadata describing the Model&#39;s input and output for explanation.</span>
<span class="sd">                Both `explanation_metadata` and `explanation_parameters` must be</span>
<span class="sd">                passed together when used. For more details, see</span>
<span class="sd">                `Ref docs &lt;http://tinyurl.com/1igh60kt&gt;`</span>
<span class="sd">            explanation_parameters (explain.ExplanationParameters):</span>
<span class="sd">                Optional. Parameters to configure explaining for Model&#39;s predictions.</span>
<span class="sd">                For more details, see `Ref docs &lt;http://tinyurl.com/1an4zake&gt;`</span>
<span class="sd">            metadata (Sequence[Tuple[str, str]]):</span>
<span class="sd">                Optional. Strings which should be sent along with the request as</span>
<span class="sd">                metadata.</span>
<span class="sd">            sync (bool):</span>
<span class="sd">                Whether to execute this method synchronously. If False, this method</span>
<span class="sd">                will be executed in concurrent Future and any downstream object will</span>
<span class="sd">                be immediately returned and synced when the Future has completed.</span>
<span class="sd">        Raises:</span>
<span class="sd">            ValueError if there is not current traffic split and traffic percentage</span>
<span class="sd">            is not 0 or 100.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">log_action_start_against_resource</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Deploying Model </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">resource_name</span><span class="si">}</span><span class="s2"> to&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="bp">self</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_deploy_call</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">api_client</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resource_name</span><span class="p">,</span>
            <span class="n">model</span><span class="o">.</span><span class="n">resource_name</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_gca_resource</span><span class="o">.</span><span class="n">traffic_split</span><span class="p">,</span>
            <span class="n">deployed_model_display_name</span><span class="o">=</span><span class="n">deployed_model_display_name</span><span class="p">,</span>
            <span class="n">traffic_percentage</span><span class="o">=</span><span class="n">traffic_percentage</span><span class="p">,</span>
            <span class="n">traffic_split</span><span class="o">=</span><span class="n">traffic_split</span><span class="p">,</span>
            <span class="n">machine_type</span><span class="o">=</span><span class="n">machine_type</span><span class="p">,</span>
            <span class="n">min_replica_count</span><span class="o">=</span><span class="n">min_replica_count</span><span class="p">,</span>
            <span class="n">max_replica_count</span><span class="o">=</span><span class="n">max_replica_count</span><span class="p">,</span>
            <span class="n">accelerator_type</span><span class="o">=</span><span class="n">accelerator_type</span><span class="p">,</span>
            <span class="n">accelerator_count</span><span class="o">=</span><span class="n">accelerator_count</span><span class="p">,</span>
            <span class="n">service_account</span><span class="o">=</span><span class="n">service_account</span><span class="p">,</span>
            <span class="n">explanation_metadata</span><span class="o">=</span><span class="n">explanation_metadata</span><span class="p">,</span>
            <span class="n">explanation_parameters</span><span class="o">=</span><span class="n">explanation_parameters</span><span class="p">,</span>
            <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">log_action_completed_against_resource</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="s2">&quot;deployed&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_sync_gca_resource</span><span class="p">()</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_deploy_call</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">api_client</span><span class="p">:</span> <span class="n">endpoint_service_client</span><span class="o">.</span><span class="n">EndpointServiceClient</span><span class="p">,</span>
        <span class="n">endpoint_resource_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">model_resource_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">endpoint_resource_traffic_split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">proto</span><span class="o">.</span><span class="n">MapField</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">deployed_model_display_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">traffic_percentage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">traffic_split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">machine_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">min_replica_count</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">max_replica_count</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">accelerator_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">accelerator_count</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">service_account</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">explanation_metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">explain</span><span class="o">.</span><span class="n">ExplanationMetadata</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">explanation_parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">explain</span><span class="o">.</span><span class="n">ExplanationParameters</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">(),</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Helper method to deploy model to endpoint.</span>

<span class="sd">        Args:</span>
<span class="sd">            api_client (endpoint_service_client.EndpointServiceClient):</span>
<span class="sd">                Required. endpoint_service_client.EndpointServiceClient to make call.</span>
<span class="sd">            endpoint_resource_name (str):</span>
<span class="sd">                Required. Endpoint resource name to deploy model to.</span>
<span class="sd">            model_resource_name (str):</span>
<span class="sd">                Required. Model resource name of Model to deploy.</span>
<span class="sd">            endpoint_resource_traffic_split (proto.MapField):</span>
<span class="sd">                Optional. Endpoint current resource traffic split.</span>
<span class="sd">            deployed_model_display_name (str):</span>
<span class="sd">                Optional. The display name of the DeployedModel. If not provided</span>
<span class="sd">                upon creation, the Model&#39;s display_name is used.</span>
<span class="sd">            traffic_percentage (int):</span>
<span class="sd">                Optional. Desired traffic to newly deployed model. Defaults to</span>
<span class="sd">                0 if there are pre-existing deployed models. Defaults to 100 if</span>
<span class="sd">                there are no pre-existing deployed models. Negative values should</span>
<span class="sd">                not be provided. Traffic of previously deployed models at the endpoint</span>
<span class="sd">                will be scaled down to accommodate new deployed model&#39;s traffic.</span>
<span class="sd">                Should not be provided if traffic_split is provided.</span>
<span class="sd">            traffic_split (Dict[str, int]):</span>
<span class="sd">                Optional. A map from a DeployedModel&#39;s ID to the percentage of</span>
<span class="sd">                this Endpoint&#39;s traffic that should be forwarded to that DeployedModel.</span>
<span class="sd">                If a DeployedModel&#39;s ID is not listed in this map, then it receives</span>
<span class="sd">                no traffic. The traffic percentage values must add up to 100, or</span>
<span class="sd">                map must be empty if the Endpoint is to not accept any traffic at</span>
<span class="sd">                the moment. Key for model being deployed is &quot;0&quot;. Should not be</span>
<span class="sd">                provided if traffic_percentage is provided.</span>
<span class="sd">            machine_type (str):</span>
<span class="sd">                Optional. The type of machine. Not specifying machine type will</span>
<span class="sd">                result in model to be deployed with automatic resources.</span>
<span class="sd">            min_replica_count (int):</span>
<span class="sd">                Optional. The minimum number of machine replicas this deployed</span>
<span class="sd">                model will be always deployed on. If traffic against it increases,</span>
<span class="sd">                it may dynamically be deployed onto more replicas, and as traffic</span>
<span class="sd">                decreases, some of these extra replicas may be freed.</span>
<span class="sd">            max_replica_count (int):</span>
<span class="sd">                Optional. The maximum number of replicas this deployed model may</span>
<span class="sd">                be deployed on when the traffic against it increases. If requested</span>
<span class="sd">                value is too large, the deployment will error, but if deployment</span>
<span class="sd">                succeeds then the ability to scale the model to that many replicas</span>
<span class="sd">                is guaranteed (barring service outages). If traffic against the</span>
<span class="sd">                deployed model increases beyond what its replicas at maximum may</span>
<span class="sd">                handle, a portion of the traffic will be dropped. If this value</span>
<span class="sd">                is not provided, the larger value of min_replica_count or 1 will</span>
<span class="sd">                be used. If value provided is smaller than min_replica_count, it</span>
<span class="sd">                will automatically be increased to be min_replica_count.</span>
<span class="sd">            service_account (str):</span>
<span class="sd">                The service account that the DeployedModel&#39;s container runs as. Specify the</span>
<span class="sd">                email address of the service account. If this service account is not</span>
<span class="sd">                specified, the container runs as a service account that doesn&#39;t have access</span>
<span class="sd">                to the resource project.</span>
<span class="sd">                Users deploying the Model must have the `iam.serviceAccounts.actAs`</span>
<span class="sd">                permission on this service account.</span>
<span class="sd">            explanation_metadata (explain.ExplanationMetadata):</span>
<span class="sd">                Optional. Metadata describing the Model&#39;s input and output for explanation.</span>
<span class="sd">                Both `explanation_metadata` and `explanation_parameters` must be</span>
<span class="sd">                passed together when used. For more details, see</span>
<span class="sd">                `Ref docs &lt;http://tinyurl.com/1igh60kt&gt;`</span>
<span class="sd">            explanation_parameters (explain.ExplanationParameters):</span>
<span class="sd">                Optional. Parameters to configure explaining for Model&#39;s predictions.</span>
<span class="sd">                For more details, see `Ref docs &lt;http://tinyurl.com/1an4zake&gt;`</span>
<span class="sd">            metadata (Sequence[Tuple[str, str]]):</span>
<span class="sd">                Optional. Strings which should be sent along with the request as</span>
<span class="sd">                metadata.</span>
<span class="sd">            sync (bool):</span>
<span class="sd">                Whether to execute this method synchronously. If False, this method</span>
<span class="sd">                will be executed in concurrent Future and any downstream object will</span>
<span class="sd">                be immediately returned and synced when the Future has completed.</span>
<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If there is not current traffic split and traffic percentage</span>
<span class="sd">                is not 0 or 100.</span>
<span class="sd">            ValueError: If only `explanation_metadata` or `explanation_parameters`</span>
<span class="sd">                is specified.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">max_replica_count</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">min_replica_count</span><span class="p">,</span> <span class="n">max_replica_count</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">bool</span><span class="p">(</span><span class="n">accelerator_type</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">accelerator_count</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Both `accelerator_type` and `accelerator_count` should be specified or None.&quot;</span>
            <span class="p">)</span>

        <span class="n">gca_endpoint</span> <span class="o">=</span> <span class="n">gca_endpoint_compat</span>
        <span class="n">gca_machine_resources</span> <span class="o">=</span> <span class="n">gca_machine_resources_compat</span>
        <span class="k">if</span> <span class="n">explanation_metadata</span> <span class="ow">and</span> <span class="n">explanation_parameters</span><span class="p">:</span>
            <span class="n">gca_endpoint</span> <span class="o">=</span> <span class="n">gca_endpoint_v1beta1</span>
            <span class="n">gca_machine_resources</span> <span class="o">=</span> <span class="n">gca_machine_resources_v1beta1</span>

        <span class="n">deployed_model</span> <span class="o">=</span> <span class="n">gca_endpoint</span><span class="o">.</span><span class="n">DeployedModel</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model_resource_name</span><span class="p">,</span>
            <span class="n">display_name</span><span class="o">=</span><span class="n">deployed_model_display_name</span><span class="p">,</span>
            <span class="n">service_account</span><span class="o">=</span><span class="n">service_account</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">machine_type</span><span class="p">:</span>
            <span class="n">machine_spec</span> <span class="o">=</span> <span class="n">gca_machine_resources</span><span class="o">.</span><span class="n">MachineSpec</span><span class="p">(</span><span class="n">machine_type</span><span class="o">=</span><span class="n">machine_type</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">accelerator_type</span> <span class="ow">and</span> <span class="n">accelerator_count</span><span class="p">:</span>
                <span class="n">utils</span><span class="o">.</span><span class="n">validate_accelerator_type</span><span class="p">(</span><span class="n">accelerator_type</span><span class="p">)</span>
                <span class="n">machine_spec</span><span class="o">.</span><span class="n">accelerator_type</span> <span class="o">=</span> <span class="n">accelerator_type</span>
                <span class="n">machine_spec</span><span class="o">.</span><span class="n">accelerator_count</span> <span class="o">=</span> <span class="n">accelerator_count</span>

            <span class="n">deployed_model</span><span class="o">.</span><span class="n">dedicated_resources</span> <span class="o">=</span> <span class="n">gca_machine_resources</span><span class="o">.</span><span class="n">DedicatedResources</span><span class="p">(</span>
                <span class="n">machine_spec</span><span class="o">=</span><span class="n">machine_spec</span><span class="p">,</span>
                <span class="n">min_replica_count</span><span class="o">=</span><span class="n">min_replica_count</span><span class="p">,</span>
                <span class="n">max_replica_count</span><span class="o">=</span><span class="n">max_replica_count</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">deployed_model</span><span class="o">.</span><span class="n">automatic_resources</span> <span class="o">=</span> <span class="n">gca_machine_resources</span><span class="o">.</span><span class="n">AutomaticResources</span><span class="p">(</span>
                <span class="n">min_replica_count</span><span class="o">=</span><span class="n">min_replica_count</span><span class="p">,</span>
                <span class="n">max_replica_count</span><span class="o">=</span><span class="n">max_replica_count</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Service will throw error if both metadata and parameters are not provided</span>
        <span class="k">if</span> <span class="n">explanation_metadata</span> <span class="ow">and</span> <span class="n">explanation_parameters</span><span class="p">:</span>
            <span class="n">api_client</span> <span class="o">=</span> <span class="n">api_client</span><span class="o">.</span><span class="n">select_version</span><span class="p">(</span><span class="n">compat</span><span class="o">.</span><span class="n">V1BETA1</span><span class="p">)</span>
            <span class="n">explanation_spec</span> <span class="o">=</span> <span class="n">gca_endpoint</span><span class="o">.</span><span class="n">explanation</span><span class="o">.</span><span class="n">ExplanationSpec</span><span class="p">()</span>
            <span class="n">explanation_spec</span><span class="o">.</span><span class="n">metadata</span> <span class="o">=</span> <span class="n">explanation_metadata</span>
            <span class="n">explanation_spec</span><span class="o">.</span><span class="n">parameters</span> <span class="o">=</span> <span class="n">explanation_parameters</span>
            <span class="n">deployed_model</span><span class="o">.</span><span class="n">explanation_spec</span> <span class="o">=</span> <span class="n">explanation_spec</span>

        <span class="k">if</span> <span class="n">traffic_split</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># new model traffic needs to be 100 if no pre-existing models</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">endpoint_resource_traffic_split</span><span class="p">:</span>
                <span class="c1"># default scenario</span>
                <span class="k">if</span> <span class="n">traffic_percentage</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">traffic_percentage</span> <span class="o">=</span> <span class="mi">100</span>
                <span class="c1"># verify user specified 100</span>
                <span class="k">elif</span> <span class="n">traffic_percentage</span> <span class="o">&lt;</span> <span class="mi">100</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sd">&quot;&quot;&quot;There are currently no deployed models so the traffic</span>
<span class="sd">                        percentage for this deployed model needs to be 100.&quot;&quot;&quot;</span>
                    <span class="p">)</span>
            <span class="n">traffic_split</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_allocate_traffic</span><span class="p">(</span>
                <span class="n">traffic_split</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">endpoint_resource_traffic_split</span><span class="p">),</span>
                <span class="n">traffic_percentage</span><span class="o">=</span><span class="n">traffic_percentage</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">operation_future</span> <span class="o">=</span> <span class="n">api_client</span><span class="o">.</span><span class="n">deploy_model</span><span class="p">(</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="n">endpoint_resource_name</span><span class="p">,</span>
            <span class="n">deployed_model</span><span class="o">=</span><span class="n">deployed_model</span><span class="p">,</span>
            <span class="n">traffic_split</span><span class="o">=</span><span class="n">traffic_split</span><span class="p">,</span>
            <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">log_action_started_against_resource_with_lro</span><span class="p">(</span>
            <span class="s2">&quot;Deploy&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="bp">cls</span><span class="p">,</span> <span class="n">operation_future</span>
        <span class="p">)</span>

        <span class="n">operation_future</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>

<div class="viewcode-block" id="Endpoint.undeploy"><a class="viewcode-back" href="../../../../aiplatform.html#google.cloud.aiplatform.Endpoint.undeploy">[docs]</a>    <span class="k">def</span> <span class="nf">undeploy</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">deployed_model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">traffic_split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">(),</span>
        <span class="n">sync</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Undeploys a deployed model.</span>

<span class="sd">        Proportionally adjusts the traffic_split among the remaining deployed</span>
<span class="sd">        models of the endpoint.</span>

<span class="sd">        Args:</span>
<span class="sd">            deployed_model_id (str):</span>
<span class="sd">                Required. The ID of the DeployedModel to be undeployed from the</span>
<span class="sd">                Endpoint.</span>
<span class="sd">            traffic_split (Dict[str, int]):</span>
<span class="sd">                Optional. A map from a DeployedModel&#39;s ID to the percentage of</span>
<span class="sd">                this Endpoint&#39;s traffic that should be forwarded to that DeployedModel.</span>
<span class="sd">                If a DeployedModel&#39;s ID is not listed in this map, then it receives</span>
<span class="sd">                no traffic. The traffic percentage values must add up to 100, or</span>
<span class="sd">                map must be empty if the Endpoint is to not accept any traffic at</span>
<span class="sd">                the moment. Key for model being deployed is &quot;0&quot;. Should not be</span>
<span class="sd">                provided if traffic_percentage is provided.</span>
<span class="sd">            metadata (Sequence[Tuple[str, str]]):</span>
<span class="sd">                Optional. Strings which should be sent along with the request as</span>
<span class="sd">                metadata.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">traffic_split</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">deployed_model_id</span> <span class="ow">in</span> <span class="n">traffic_split</span> <span class="ow">and</span> <span class="n">traffic_split</span><span class="p">[</span><span class="n">deployed_model_id</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model being undeployed should have 0 traffic.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">traffic_split</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="o">!=</span> <span class="mi">100</span><span class="p">:</span>
                <span class="c1"># TODO(b/172678233) verify every referenced deployed model exists</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Sum of all traffic within traffic split needs to be 100.&quot;</span>
                <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_undeploy</span><span class="p">(</span>
            <span class="n">deployed_model_id</span><span class="o">=</span><span class="n">deployed_model_id</span><span class="p">,</span>
            <span class="n">traffic_split</span><span class="o">=</span><span class="n">traffic_split</span><span class="p">,</span>
            <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
            <span class="n">sync</span><span class="o">=</span><span class="n">sync</span><span class="p">,</span>
        <span class="p">)</span></div>

    <span class="nd">@base</span><span class="o">.</span><span class="n">optional_sync</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">_undeploy</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">deployed_model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">traffic_split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">(),</span>
        <span class="n">sync</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Undeploys a deployed model.</span>

<span class="sd">        Proportionally adjusts the traffic_split among the remaining deployed</span>
<span class="sd">        models of the endpoint.</span>

<span class="sd">        Args:</span>
<span class="sd">            deployed_model_id (str):</span>
<span class="sd">                Required. The ID of the DeployedModel to be undeployed from the</span>
<span class="sd">                Endpoint.</span>
<span class="sd">            traffic_split (Dict[str, int]):</span>
<span class="sd">                Optional. A map from a DeployedModel&#39;s ID to the percentage of</span>
<span class="sd">                this Endpoint&#39;s traffic that should be forwarded to that DeployedModel.</span>
<span class="sd">                If a DeployedModel&#39;s ID is not listed in this map, then it receives</span>
<span class="sd">                no traffic. The traffic percentage values must add up to 100, or</span>
<span class="sd">                map must be empty if the Endpoint is to not accept any traffic at</span>
<span class="sd">                the moment. Key for model being deployed is &quot;0&quot;. Should not be</span>
<span class="sd">                provided if traffic_percentage is provided.</span>
<span class="sd">            metadata (Sequence[Tuple[str, str]]):</span>
<span class="sd">                Optional. Strings which should be sent along with the request as</span>
<span class="sd">                metadata.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">current_traffic_split</span> <span class="o">=</span> <span class="n">traffic_split</span> <span class="ow">or</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_gca_resource</span><span class="o">.</span><span class="n">traffic_split</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">deployed_model_id</span> <span class="ow">in</span> <span class="n">current_traffic_split</span><span class="p">:</span>
            <span class="n">current_traffic_split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unallocate_traffic</span><span class="p">(</span>
                <span class="n">traffic_split</span><span class="o">=</span><span class="n">current_traffic_split</span><span class="p">,</span>
                <span class="n">deployed_model_id</span><span class="o">=</span><span class="n">deployed_model_id</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">current_traffic_split</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">deployed_model_id</span><span class="p">)</span>

        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">log_action_start_against_resource</span><span class="p">(</span><span class="s2">&quot;Undeploying&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

        <span class="n">operation_future</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">api_client</span><span class="o">.</span><span class="n">undeploy_model</span><span class="p">(</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">resource_name</span><span class="p">,</span>
            <span class="n">deployed_model_id</span><span class="o">=</span><span class="n">deployed_model_id</span><span class="p">,</span>
            <span class="n">traffic_split</span><span class="o">=</span><span class="n">current_traffic_split</span><span class="p">,</span>
            <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">log_action_started_against_resource_with_lro</span><span class="p">(</span>
            <span class="s2">&quot;Undeploy&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">,</span> <span class="n">operation_future</span>
        <span class="p">)</span>

        <span class="c1"># block before returning</span>
        <span class="n">operation_future</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>

        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">log_action_completed_against_resource</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="s2">&quot;undeployed&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

        <span class="c1"># update local resource</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sync_gca_resource</span><span class="p">()</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_instantiate_prediction_client</span><span class="p">(</span>
        <span class="n">location</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">credentials</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">auth_credentials</span><span class="o">.</span><span class="n">Credentials</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">utils</span><span class="o">.</span><span class="n">PredictionClientWithOverride</span><span class="p">:</span>

        <span class="sd">&quot;&quot;&quot;Helper method to instantiates prediction client with optional</span>
<span class="sd">        overrides for this endpoint.</span>

<span class="sd">        Args:</span>
<span class="sd">            location (str): The location of this endpoint.</span>
<span class="sd">            credentials (google.auth.credentials.Credentials):</span>
<span class="sd">                Optional custom credentials to use when accessing interacting with</span>
<span class="sd">                the prediction client.</span>
<span class="sd">        Returns:</span>
<span class="sd">            prediction_client (prediction_service_client.PredictionServiceClient):</span>
<span class="sd">                Initalized prediction client with optional overrides.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">initializer</span><span class="o">.</span><span class="n">global_config</span><span class="o">.</span><span class="n">create_client</span><span class="p">(</span>
            <span class="n">client_class</span><span class="o">=</span><span class="n">utils</span><span class="o">.</span><span class="n">PredictionClientWithOverride</span><span class="p">,</span>
            <span class="n">credentials</span><span class="o">=</span><span class="n">credentials</span><span class="p">,</span>
            <span class="n">location_override</span><span class="o">=</span><span class="n">location</span><span class="p">,</span>
            <span class="n">prediction_client</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

<div class="viewcode-block" id="Endpoint.predict"><a class="viewcode-back" href="../../../../aiplatform.html#google.cloud.aiplatform.Endpoint.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">instances</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span> <span class="n">parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Prediction</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Make a prediction against this Endpoint.</span>

<span class="sd">        Args:</span>
<span class="sd">            instances (List):</span>
<span class="sd">                Required. The instances that are the input to the</span>
<span class="sd">                prediction call. A DeployedModel may have an upper limit</span>
<span class="sd">                on the number of instances it supports per request, and</span>
<span class="sd">                when it is exceeded the prediction call errors in case</span>
<span class="sd">                of AutoML Models, or, in case of customer created</span>
<span class="sd">                Models, the behaviour is as documented by that Model.</span>
<span class="sd">                The schema of any single instance may be specified via</span>
<span class="sd">                Endpoint&#39;s DeployedModels&#39;</span>
<span class="sd">                [Model&#39;s][google.cloud.aiplatform.v1beta1.DeployedModel.model]</span>
<span class="sd">                [PredictSchemata&#39;s][google.cloud.aiplatform.v1beta1.Model.predict_schemata]</span>
<span class="sd">                ``instance_schema_uri``.</span>
<span class="sd">            parameters (Dict):</span>
<span class="sd">                The parameters that govern the prediction. The schema of</span>
<span class="sd">                the parameters may be specified via Endpoint&#39;s</span>
<span class="sd">                DeployedModels&#39; [Model&#39;s</span>
<span class="sd">                ][google.cloud.aiplatform.v1beta1.DeployedModel.model]</span>
<span class="sd">                [PredictSchemata&#39;s][google.cloud.aiplatform.v1beta1.Model.predict_schemata]</span>
<span class="sd">                ``parameters_schema_uri``.</span>
<span class="sd">        Returns:</span>
<span class="sd">            prediction: Prediction with returned predictions and Model Id.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

        <span class="n">prediction_response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prediction_client</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">resource_name</span><span class="p">,</span> <span class="n">instances</span><span class="o">=</span><span class="n">instances</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">Prediction</span><span class="p">(</span>
            <span class="n">predictions</span><span class="o">=</span><span class="p">[</span>
                <span class="n">json_format</span><span class="o">.</span><span class="n">MessageToDict</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">prediction_response</span><span class="o">.</span><span class="n">predictions</span><span class="o">.</span><span class="n">pb</span>
            <span class="p">],</span>
            <span class="n">deployed_model_id</span><span class="o">=</span><span class="n">prediction_response</span><span class="o">.</span><span class="n">deployed_model_id</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Endpoint.explain"><a class="viewcode-back" href="../../../../aiplatform.html#google.cloud.aiplatform.Endpoint.explain">[docs]</a>    <span class="k">def</span> <span class="nf">explain</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">instances</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">],</span>
        <span class="n">parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">deployed_model_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Prediction</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Make a prediction with explanations against this Endpoint.</span>

<span class="sd">        Example usage:</span>
<span class="sd">            response = my_endpoint.explain(instances=[...])</span>
<span class="sd">            my_explanations = response.explanations</span>

<span class="sd">        Args:</span>
<span class="sd">            instances (List):</span>
<span class="sd">                Required. The instances that are the input to the</span>
<span class="sd">                prediction call. A DeployedModel may have an upper limit</span>
<span class="sd">                on the number of instances it supports per request, and</span>
<span class="sd">                when it is exceeded the prediction call errors in case</span>
<span class="sd">                of AutoML Models, or, in case of customer created</span>
<span class="sd">                Models, the behaviour is as documented by that Model.</span>
<span class="sd">                The schema of any single instance may be specified via</span>
<span class="sd">                Endpoint&#39;s DeployedModels&#39;</span>
<span class="sd">                [Model&#39;s][google.cloud.aiplatform.v1beta1.DeployedModel.model]</span>
<span class="sd">                [PredictSchemata&#39;s][google.cloud.aiplatform.v1beta1.Model.predict_schemata]</span>
<span class="sd">                ``instance_schema_uri``.</span>
<span class="sd">            parameters (Dict):</span>
<span class="sd">                The parameters that govern the prediction. The schema of</span>
<span class="sd">                the parameters may be specified via Endpoint&#39;s</span>
<span class="sd">                DeployedModels&#39; [Model&#39;s</span>
<span class="sd">                ][google.cloud.aiplatform.v1beta1.DeployedModel.model]</span>
<span class="sd">                [PredictSchemata&#39;s][google.cloud.aiplatform.v1beta1.Model.predict_schemata]</span>
<span class="sd">                ``parameters_schema_uri``.</span>
<span class="sd">            deployed_model_id (str):</span>
<span class="sd">                Optional. If specified, this ExplainRequest will be served by the</span>
<span class="sd">                chosen DeployedModel, overriding this Endpoint&#39;s traffic split.</span>
<span class="sd">        Returns:</span>
<span class="sd">            prediction: Prediction with returned predictions, explanations and Model Id.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

        <span class="n">explain_response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prediction_client</span><span class="o">.</span><span class="n">select_version</span><span class="p">(</span>
            <span class="n">compat</span><span class="o">.</span><span class="n">V1BETA1</span>
        <span class="p">)</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">resource_name</span><span class="p">,</span>
            <span class="n">instances</span><span class="o">=</span><span class="n">instances</span><span class="p">,</span>
            <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
            <span class="n">deployed_model_id</span><span class="o">=</span><span class="n">deployed_model_id</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">Prediction</span><span class="p">(</span>
            <span class="n">predictions</span><span class="o">=</span><span class="p">[</span>
                <span class="n">json_format</span><span class="o">.</span><span class="n">MessageToDict</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">explain_response</span><span class="o">.</span><span class="n">predictions</span><span class="o">.</span><span class="n">pb</span>
            <span class="p">],</span>
            <span class="n">deployed_model_id</span><span class="o">=</span><span class="n">explain_response</span><span class="o">.</span><span class="n">deployed_model_id</span><span class="p">,</span>
            <span class="n">explanations</span><span class="o">=</span><span class="n">explain_response</span><span class="o">.</span><span class="n">explanations</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Endpoint.list"><a class="viewcode-back" href="../../../../aiplatform.html#google.cloud.aiplatform.Endpoint.list">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">list</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="nb">filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">order_by</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">project</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">location</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">credentials</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">auth_credentials</span><span class="o">.</span><span class="n">Credentials</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;models.Endpoint&quot;</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;List all Endpoint resource instances.</span>

<span class="sd">        Example Usage:</span>

<span class="sd">        aiplatform.Endpoint.list(</span>
<span class="sd">            filter=&#39;labels.my_label=&quot;my_label_value&quot; OR display_name=!&quot;old_endpoint&quot;&#39;,</span>
<span class="sd">        )</span>

<span class="sd">        Args:</span>
<span class="sd">            filter (str):</span>
<span class="sd">                Optional. An expression for filtering the results of the request.</span>
<span class="sd">                For field names both snake_case and camelCase are supported.</span>
<span class="sd">            order_by (str):</span>
<span class="sd">                Optional. A comma-separated list of fields to order by, sorted in</span>
<span class="sd">                ascending order. Use &quot;desc&quot; after a field name for descending.</span>
<span class="sd">                Supported fields: `display_name`, `create_time`, `update_time`</span>
<span class="sd">            project (str):</span>
<span class="sd">                Optional. Project to retrieve list from. If not set, project</span>
<span class="sd">                set in aiplatform.init will be used.</span>
<span class="sd">            location (str):</span>
<span class="sd">                Optional. Location to retrieve list from. If not set, location</span>
<span class="sd">                set in aiplatform.init will be used.</span>
<span class="sd">            credentials (auth_credentials.Credentials):</span>
<span class="sd">                Optional. Custom credentials to use to retrieve list. Overrides</span>
<span class="sd">                credentials set in aiplatform.init.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[models.Endpoint] - A list of Endpoint resource objects</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_list_with_local_order</span><span class="p">(</span>
            <span class="nb">filter</span><span class="o">=</span><span class="nb">filter</span><span class="p">,</span>
            <span class="n">order_by</span><span class="o">=</span><span class="n">order_by</span><span class="p">,</span>
            <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span>
            <span class="n">location</span><span class="o">=</span><span class="n">location</span><span class="p">,</span>
            <span class="n">credentials</span><span class="o">=</span><span class="n">credentials</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Endpoint.list_models"><a class="viewcode-back" href="../../../../aiplatform.html#google.cloud.aiplatform.Endpoint.list_models">[docs]</a>    <span class="k">def</span> <span class="nf">list_models</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span>
        <span class="n">Union</span><span class="p">[</span><span class="n">gca_endpoint_v1</span><span class="o">.</span><span class="n">DeployedModel</span><span class="p">,</span> <span class="n">gca_endpoint_v1beta1</span><span class="o">.</span><span class="n">DeployedModel</span><span class="p">]</span>
    <span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns a list of the models deployed to this Endpoint.</span>

<span class="sd">        Returns:</span>
<span class="sd">            deployed_models (Sequence[aiplatform.gapic.DeployedModel]):</span>
<span class="sd">                A list of the models deployed in this Endpoint.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sync_gca_resource</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gca_resource</span><span class="o">.</span><span class="n">deployed_models</span></div>

<div class="viewcode-block" id="Endpoint.undeploy_all"><a class="viewcode-back" href="../../../../aiplatform.html#google.cloud.aiplatform.Endpoint.undeploy_all">[docs]</a>    <span class="k">def</span> <span class="nf">undeploy_all</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sync</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Endpoint&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Undeploys every model deployed to this Endpoint.</span>

<span class="sd">        Args:</span>
<span class="sd">            sync (bool):</span>
<span class="sd">                Whether to execute this method synchronously. If False, this method</span>
<span class="sd">                will be executed in concurrent Future and any downstream object will</span>
<span class="sd">                be immediately returned and synced when the Future has completed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sync_gca_resource</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">deployed_model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gca_resource</span><span class="o">.</span><span class="n">deployed_models</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_undeploy</span><span class="p">(</span><span class="n">deployed_model_id</span><span class="o">=</span><span class="n">deployed_model</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="n">sync</span><span class="o">=</span><span class="n">sync</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="Endpoint.delete"><a class="viewcode-back" href="../../../../aiplatform.html#google.cloud.aiplatform.Endpoint.delete">[docs]</a>    <span class="k">def</span> <span class="nf">delete</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">force</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">sync</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Deletes this Vertex AI Endpoint resource. If force is set to True,</span>
<span class="sd">        all models on this Endpoint will be undeployed prior to deletion.</span>

<span class="sd">        Args:</span>
<span class="sd">            force (bool):</span>
<span class="sd">                Required. If force is set to True, all deployed models on this</span>
<span class="sd">                Endpoint will be undeployed first. Default is False.</span>
<span class="sd">            sync (bool):</span>
<span class="sd">                Whether to execute this method synchronously. If False, this method</span>
<span class="sd">                will be executed in concurrent Future and any downstream object will</span>
<span class="sd">                be immediately returned and synced when the Future has completed.</span>
<span class="sd">        Raises:</span>
<span class="sd">            FailedPrecondition: If models are deployed on this Endpoint and force = False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">force</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">undeploy_all</span><span class="p">(</span><span class="n">sync</span><span class="o">=</span><span class="n">sync</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">sync</span><span class="o">=</span><span class="n">sync</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="Model"><a class="viewcode-back" href="../../../../aiplatform.html#google.cloud.aiplatform.Model">[docs]</a><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">base</span><span class="o">.</span><span class="n">VertexAiResourceNounWithFutureManager</span><span class="p">):</span>

    <span class="n">client_class</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">ModelClientWithOverride</span>
    <span class="n">_is_client_prediction_client</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">_resource_noun</span> <span class="o">=</span> <span class="s2">&quot;models&quot;</span>
    <span class="n">_getter_method</span> <span class="o">=</span> <span class="s2">&quot;get_model&quot;</span>
    <span class="n">_list_method</span> <span class="o">=</span> <span class="s2">&quot;list_models&quot;</span>
    <span class="n">_delete_method</span> <span class="o">=</span> <span class="s2">&quot;delete_model&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">uri</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Uri of the model.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gca_resource</span><span class="o">.</span><span class="n">artifact_uri</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">description</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Description of the model.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gca_resource</span><span class="o">.</span><span class="n">description</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">supported_export_formats</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">gca_model_compat</span><span class="o">.</span><span class="n">Model</span><span class="o">.</span><span class="n">ExportFormat</span><span class="o">.</span><span class="n">ExportableContent</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;The formats and content types in which this Model may be exported.</span>
<span class="sd">        If empty, this Model is not available for export.</span>

<span class="sd">        For example, if this model can be exported as a Tensorflow SavedModel and</span>
<span class="sd">        have the artifacts written to Cloud Storage, the expected value would be:</span>

<span class="sd">            {&#39;tf-saved-model&#39;: [&lt;ExportableContent.ARTIFACT: 1&gt;]}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="n">export_format</span><span class="o">.</span><span class="n">id</span><span class="p">:</span> <span class="p">[</span>
                <span class="n">gca_model_compat</span><span class="o">.</span><span class="n">Model</span><span class="o">.</span><span class="n">ExportFormat</span><span class="o">.</span><span class="n">ExportableContent</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">content</span> <span class="ow">in</span> <span class="n">export_format</span><span class="o">.</span><span class="n">exportable_contents</span>
            <span class="p">]</span>
            <span class="k">for</span> <span class="n">export_format</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gca_resource</span><span class="o">.</span><span class="n">supported_export_formats</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">project</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">location</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">credentials</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">auth_credentials</span><span class="o">.</span><span class="n">Credentials</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieves the model resource and instantiates its representation.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_name (str):</span>
<span class="sd">                Required. A fully-qualified model resource name or model ID.</span>
<span class="sd">                Example: &quot;projects/123/locations/us-central1/models/456&quot; or</span>
<span class="sd">                &quot;456&quot; when project and location are initialized or passed.</span>
<span class="sd">            project (str):</span>
<span class="sd">                Optional project to retrieve model from. If not set, project</span>
<span class="sd">                set in aiplatform.init will be used.</span>
<span class="sd">            location (str):</span>
<span class="sd">                Optional location to retrieve model from. If not set, location</span>
<span class="sd">                set in aiplatform.init will be used.</span>
<span class="sd">            credentials: Optional[auth_credentials.Credentials]=None,</span>
<span class="sd">                Custom credentials to use to upload this model. If not set,</span>
<span class="sd">                credentials set in aiplatform.init will be used.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span>
            <span class="n">location</span><span class="o">=</span><span class="n">location</span><span class="p">,</span>
            <span class="n">credentials</span><span class="o">=</span><span class="n">credentials</span><span class="p">,</span>
            <span class="n">resource_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_gca_resource</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_gca_resource</span><span class="p">(</span><span class="n">resource_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">)</span>

    <span class="c1"># TODO(b/170979552) Add support for predict schemata</span>
    <span class="c1"># TODO(b/170979926) Add support for metadata and metadata schema</span>
<div class="viewcode-block" id="Model.upload"><a class="viewcode-back" href="../../../../aiplatform.html#google.cloud.aiplatform.Model.upload">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="nd">@base</span><span class="o">.</span><span class="n">optional_sync</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">upload</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">display_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">serving_container_image_uri</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">artifact_uri</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">serving_container_predict_route</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">serving_container_health_route</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">description</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">serving_container_command</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">serving_container_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">serving_container_environment_variables</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">serving_container_ports</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">instance_schema_uri</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">parameters_schema_uri</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prediction_schema_uri</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">explanation_metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">explain</span><span class="o">.</span><span class="n">ExplanationMetadata</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">explanation_parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">explain</span><span class="o">.</span><span class="n">ExplanationParameters</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">project</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">location</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">credentials</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">auth_credentials</span><span class="o">.</span><span class="n">Credentials</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">encryption_spec_key_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sync</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Model&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Uploads a model and returns a Model representing the uploaded Model</span>
<span class="sd">        resource.</span>

<span class="sd">        Example usage:</span>

<span class="sd">        my_model = Model.upload(</span>
<span class="sd">            display_name=&#39;my-model&#39;,</span>
<span class="sd">            artifact_uri=&#39;gs://my-model/saved-model&#39;</span>
<span class="sd">            serving_container_image_uri=&#39;tensorflow/serving&#39;</span>
<span class="sd">        )</span>

<span class="sd">        Args:</span>
<span class="sd">            display_name (str):</span>
<span class="sd">                Required. The display name of the Model. The name can be up to 128</span>
<span class="sd">                characters long and can be consist of any UTF-8 characters.</span>
<span class="sd">            serving_container_image_uri (str):</span>
<span class="sd">                Required. The URI of the Model serving container.</span>
<span class="sd">            artifact_uri (str):</span>
<span class="sd">                Optional. The path to the directory containing the Model artifact and</span>
<span class="sd">                any of its supporting files. Leave blank for custom container prediction.</span>
<span class="sd">                Not present for AutoML Models.</span>
<span class="sd">            serving_container_predict_route (str):</span>
<span class="sd">                Optional. An HTTP path to send prediction requests to the container, and</span>
<span class="sd">                which must be supported by it. If not specified a default HTTP path will</span>
<span class="sd">                be used by Vertex AI.</span>
<span class="sd">            serving_container_health_route (str):</span>
<span class="sd">                Optional. An HTTP path to send health check requests to the container, and which</span>
<span class="sd">                must be supported by it. If not specified a standard HTTP path will be</span>
<span class="sd">                used by Vertex AI.</span>
<span class="sd">            description (str):</span>
<span class="sd">                The description of the model.</span>
<span class="sd">            serving_container_command: Optional[Sequence[str]]=None,</span>
<span class="sd">                The command with which the container is run. Not executed within a</span>
<span class="sd">                shell. The Docker image&#39;s ENTRYPOINT is used if this is not provided.</span>
<span class="sd">                Variable references $(VAR_NAME) are expanded using the container&#39;s</span>
<span class="sd">                environment. If a variable cannot be resolved, the reference in the</span>
<span class="sd">                input string will be unchanged. The $(VAR_NAME) syntax can be escaped</span>
<span class="sd">                with a double $$, ie: $$(VAR_NAME). Escaped references will never be</span>
<span class="sd">                expanded, regardless of whether the variable exists or not.</span>
<span class="sd">            serving_container_args: Optional[Sequence[str]]=None,</span>
<span class="sd">                The arguments to the command. The Docker image&#39;s CMD is used if this is</span>
<span class="sd">                not provided. Variable references $(VAR_NAME) are expanded using the</span>
<span class="sd">                container&#39;s environment. If a variable cannot be resolved, the reference</span>
<span class="sd">                in the input string will be unchanged. The $(VAR_NAME) syntax can be</span>
<span class="sd">                escaped with a double $$, ie: $$(VAR_NAME). Escaped references will</span>
<span class="sd">                never be expanded, regardless of whether the variable exists or not.</span>
<span class="sd">            serving_container_environment_variables: Optional[Dict[str, str]]=None,</span>
<span class="sd">                The environment variables that are to be present in the container.</span>
<span class="sd">                Should be a dictionary where keys are environment variable names</span>
<span class="sd">                and values are environment variable values for those names.</span>
<span class="sd">            serving_container_ports: Optional[Sequence[int]]=None,</span>
<span class="sd">                Declaration of ports that are exposed by the container. This field is</span>
<span class="sd">                primarily informational, it gives Vertex AI information about the</span>
<span class="sd">                network connections the container uses. Listing or not a port here has</span>
<span class="sd">                no impact on whether the port is actually exposed, any port listening on</span>
<span class="sd">                the default &quot;0.0.0.0&quot; address inside a container will be accessible from</span>
<span class="sd">                the network.</span>
<span class="sd">            instance_schema_uri (str):</span>
<span class="sd">                Optional. Points to a YAML file stored on Google Cloud</span>
<span class="sd">                Storage describing the format of a single instance, which</span>
<span class="sd">                are used in</span>
<span class="sd">                ``PredictRequest.instances``,</span>
<span class="sd">                ``ExplainRequest.instances``</span>
<span class="sd">                and</span>
<span class="sd">                ``BatchPredictionJob.input_config``.</span>
<span class="sd">                The schema is defined as an OpenAPI 3.0.2 `Schema</span>
<span class="sd">                Object &lt;https://tinyurl.com/y538mdwt#schema-object&gt;`__.</span>
<span class="sd">                AutoML Models always have this field populated by AI</span>
<span class="sd">                Platform. Note: The URI given on output will be immutable</span>
<span class="sd">                and probably different, including the URI scheme, than the</span>
<span class="sd">                one given on input. The output URI will point to a location</span>
<span class="sd">                where the user only has a read access.</span>
<span class="sd">            parameters_schema_uri (str):</span>
<span class="sd">                Optional. Points to a YAML file stored on Google Cloud</span>
<span class="sd">                Storage describing the parameters of prediction and</span>
<span class="sd">                explanation via</span>
<span class="sd">                ``PredictRequest.parameters``,</span>
<span class="sd">                ``ExplainRequest.parameters``</span>
<span class="sd">                and</span>
<span class="sd">                ``BatchPredictionJob.model_parameters``.</span>
<span class="sd">                The schema is defined as an OpenAPI 3.0.2 `Schema</span>
<span class="sd">                Object &lt;https://tinyurl.com/y538mdwt#schema-object&gt;`__.</span>
<span class="sd">                AutoML Models always have this field populated by AI</span>
<span class="sd">                Platform, if no parameters are supported it is set to an</span>
<span class="sd">                empty string. Note: The URI given on output will be</span>
<span class="sd">                immutable and probably different, including the URI scheme,</span>
<span class="sd">                than the one given on input. The output URI will point to a</span>
<span class="sd">                location where the user only has a read access.</span>
<span class="sd">            prediction_schema_uri (str):</span>
<span class="sd">                Optional. Points to a YAML file stored on Google Cloud</span>
<span class="sd">                Storage describing the format of a single prediction</span>
<span class="sd">                produced by this Model, which are returned via</span>
<span class="sd">                ``PredictResponse.predictions``,</span>
<span class="sd">                ``ExplainResponse.explanations``,</span>
<span class="sd">                and</span>
<span class="sd">                ``BatchPredictionJob.output_config``.</span>
<span class="sd">                The schema is defined as an OpenAPI 3.0.2 `Schema</span>
<span class="sd">                Object &lt;https://tinyurl.com/y538mdwt#schema-object&gt;`__.</span>
<span class="sd">                AutoML Models always have this field populated by AI</span>
<span class="sd">                Platform. Note: The URI given on output will be immutable</span>
<span class="sd">                and probably different, including the URI scheme, than the</span>
<span class="sd">                one given on input. The output URI will point to a location</span>
<span class="sd">                where the user only has a read access.</span>
<span class="sd">            explanation_metadata (explain.ExplanationMetadata):</span>
<span class="sd">                Optional. Metadata describing the Model&#39;s input and output for explanation.</span>
<span class="sd">                Both `explanation_metadata` and `explanation_parameters` must be</span>
<span class="sd">                passed together when used. For more details, see</span>
<span class="sd">                `Ref docs &lt;http://tinyurl.com/1igh60kt&gt;`</span>
<span class="sd">            explanation_parameters (explain.ExplanationParameters):</span>
<span class="sd">                Optional. Parameters to configure explaining for Model&#39;s predictions.</span>
<span class="sd">                For more details, see `Ref docs &lt;http://tinyurl.com/1an4zake&gt;`</span>
<span class="sd">            project: Optional[str]=None,</span>
<span class="sd">                Project to upload this model to. Overrides project set in</span>
<span class="sd">                aiplatform.init.</span>
<span class="sd">            location: Optional[str]=None,</span>
<span class="sd">                Location to upload this model to. Overrides location set in</span>
<span class="sd">                aiplatform.init.</span>
<span class="sd">            credentials: Optional[auth_credentials.Credentials]=None,</span>
<span class="sd">                Custom credentials to use to upload this model. Overrides credentials</span>
<span class="sd">                set in aiplatform.init.</span>
<span class="sd">            encryption_spec_key_name (Optional[str]):</span>
<span class="sd">                Optional. The Cloud KMS resource identifier of the customer</span>
<span class="sd">                managed encryption key used to protect the model. Has the</span>
<span class="sd">                form:</span>
<span class="sd">                ``projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key``.</span>
<span class="sd">                The key needs to be in the same region as where the compute</span>
<span class="sd">                resource is created.</span>

<span class="sd">                If set, this Model and all sub-resources of this Model will be secured by this key.</span>

<span class="sd">                Overrides encryption_spec_key_name set in aiplatform.init.</span>
<span class="sd">        Returns:</span>
<span class="sd">            model: Instantiated representation of the uploaded model resource.</span>
<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If only `explanation_metadata` or `explanation_parameters`</span>
<span class="sd">                is specified.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">validate_display_name</span><span class="p">(</span><span class="n">display_name</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">bool</span><span class="p">(</span><span class="n">explanation_metadata</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">explanation_parameters</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Both `explanation_metadata` and `explanation_parameters` should be specified or None.&quot;</span>
            <span class="p">)</span>

        <span class="n">gca_endpoint</span> <span class="o">=</span> <span class="n">gca_endpoint_compat</span>
        <span class="n">gca_model</span> <span class="o">=</span> <span class="n">gca_model_compat</span>
        <span class="n">gca_env_var</span> <span class="o">=</span> <span class="n">gca_env_var_compat</span>
        <span class="k">if</span> <span class="n">explanation_metadata</span> <span class="ow">and</span> <span class="n">explanation_parameters</span><span class="p">:</span>
            <span class="n">gca_endpoint</span> <span class="o">=</span> <span class="n">gca_endpoint_v1beta1</span>
            <span class="n">gca_model</span> <span class="o">=</span> <span class="n">gca_model_v1beta1</span>
            <span class="n">gca_env_var</span> <span class="o">=</span> <span class="n">gca_env_var_v1beta1</span>

        <span class="n">api_client</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_instantiate_client</span><span class="p">(</span><span class="n">location</span><span class="p">,</span> <span class="n">credentials</span><span class="p">)</span>
        <span class="n">env</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">ports</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">serving_container_environment_variables</span><span class="p">:</span>
            <span class="n">env</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">gca_env_var</span><span class="o">.</span><span class="n">EnvVar</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">key</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">serving_container_environment_variables</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">]</span>
        <span class="k">if</span> <span class="n">serving_container_ports</span><span class="p">:</span>
            <span class="n">ports</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">gca_model</span><span class="o">.</span><span class="n">Port</span><span class="p">(</span><span class="n">container_port</span><span class="o">=</span><span class="n">port</span><span class="p">)</span> <span class="k">for</span> <span class="n">port</span> <span class="ow">in</span> <span class="n">serving_container_ports</span>
            <span class="p">]</span>

        <span class="n">container_spec</span> <span class="o">=</span> <span class="n">gca_model</span><span class="o">.</span><span class="n">ModelContainerSpec</span><span class="p">(</span>
            <span class="n">image_uri</span><span class="o">=</span><span class="n">serving_container_image_uri</span><span class="p">,</span>
            <span class="n">command</span><span class="o">=</span><span class="n">serving_container_command</span><span class="p">,</span>
            <span class="n">args</span><span class="o">=</span><span class="n">serving_container_args</span><span class="p">,</span>
            <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">,</span>
            <span class="n">ports</span><span class="o">=</span><span class="n">ports</span><span class="p">,</span>
            <span class="n">predict_route</span><span class="o">=</span><span class="n">serving_container_predict_route</span><span class="p">,</span>
            <span class="n">health_route</span><span class="o">=</span><span class="n">serving_container_health_route</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">model_predict_schemata</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">([</span><span class="n">instance_schema_uri</span><span class="p">,</span> <span class="n">parameters_schema_uri</span><span class="p">,</span> <span class="n">prediction_schema_uri</span><span class="p">]):</span>
            <span class="n">model_predict_schemata</span> <span class="o">=</span> <span class="n">gca_model</span><span class="o">.</span><span class="n">PredictSchemata</span><span class="p">(</span>
                <span class="n">instance_schema_uri</span><span class="o">=</span><span class="n">instance_schema_uri</span><span class="p">,</span>
                <span class="n">parameters_schema_uri</span><span class="o">=</span><span class="n">parameters_schema_uri</span><span class="p">,</span>
                <span class="n">prediction_schema_uri</span><span class="o">=</span><span class="n">prediction_schema_uri</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># TODO(b/182388545) initializer.global_config.get_encryption_spec from a sync function</span>
        <span class="n">encryption_spec</span> <span class="o">=</span> <span class="n">initializer</span><span class="o">.</span><span class="n">global_config</span><span class="o">.</span><span class="n">get_encryption_spec</span><span class="p">(</span>
            <span class="n">encryption_spec_key_name</span><span class="o">=</span><span class="n">encryption_spec_key_name</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">managed_model</span> <span class="o">=</span> <span class="n">gca_model</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
            <span class="n">display_name</span><span class="o">=</span><span class="n">display_name</span><span class="p">,</span>
            <span class="n">description</span><span class="o">=</span><span class="n">description</span><span class="p">,</span>
            <span class="n">container_spec</span><span class="o">=</span><span class="n">container_spec</span><span class="p">,</span>
            <span class="n">predict_schemata</span><span class="o">=</span><span class="n">model_predict_schemata</span><span class="p">,</span>
            <span class="n">encryption_spec</span><span class="o">=</span><span class="n">encryption_spec</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">artifact_uri</span><span class="p">:</span>
            <span class="n">managed_model</span><span class="o">.</span><span class="n">artifact_uri</span> <span class="o">=</span> <span class="n">artifact_uri</span>

        <span class="c1"># Override explanation_spec if both required fields are provided</span>
        <span class="k">if</span> <span class="n">explanation_metadata</span> <span class="ow">and</span> <span class="n">explanation_parameters</span><span class="p">:</span>
            <span class="n">api_client</span> <span class="o">=</span> <span class="n">api_client</span><span class="o">.</span><span class="n">select_version</span><span class="p">(</span><span class="n">compat</span><span class="o">.</span><span class="n">V1BETA1</span><span class="p">)</span>
            <span class="n">explanation_spec</span> <span class="o">=</span> <span class="n">gca_endpoint</span><span class="o">.</span><span class="n">explanation</span><span class="o">.</span><span class="n">ExplanationSpec</span><span class="p">()</span>
            <span class="n">explanation_spec</span><span class="o">.</span><span class="n">metadata</span> <span class="o">=</span> <span class="n">explanation_metadata</span>
            <span class="n">explanation_spec</span><span class="o">.</span><span class="n">parameters</span> <span class="o">=</span> <span class="n">explanation_parameters</span>
            <span class="n">managed_model</span><span class="o">.</span><span class="n">explanation_spec</span> <span class="o">=</span> <span class="n">explanation_spec</span>

        <span class="n">lro</span> <span class="o">=</span> <span class="n">api_client</span><span class="o">.</span><span class="n">upload_model</span><span class="p">(</span>
            <span class="n">parent</span><span class="o">=</span><span class="n">initializer</span><span class="o">.</span><span class="n">global_config</span><span class="o">.</span><span class="n">common_location_path</span><span class="p">(</span><span class="n">project</span><span class="p">,</span> <span class="n">location</span><span class="p">),</span>
            <span class="n">model</span><span class="o">=</span><span class="n">managed_model</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">log_create_with_lro</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">lro</span><span class="p">)</span>

        <span class="n">model_upload_response</span> <span class="o">=</span> <span class="n">lro</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>

        <span class="n">this_model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">model_upload_response</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">log_create_complete</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">this_model</span><span class="o">.</span><span class="n">_gca_resource</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">this_model</span></div>

    <span class="c1"># TODO(b/172502059) support deploying with endpoint resource name</span>
<div class="viewcode-block" id="Model.deploy"><a class="viewcode-back" href="../../../../aiplatform.html#google.cloud.aiplatform.Model.deploy">[docs]</a>    <span class="k">def</span> <span class="nf">deploy</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">endpoint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;Endpoint&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">deployed_model_display_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">traffic_percentage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">traffic_split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">machine_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">min_replica_count</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">max_replica_count</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">accelerator_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">accelerator_count</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">service_account</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">explanation_metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">explain</span><span class="o">.</span><span class="n">ExplanationMetadata</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">explanation_parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">explain</span><span class="o">.</span><span class="n">ExplanationParameters</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">(),</span>
        <span class="n">encryption_spec_key_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sync</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Endpoint</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Deploys model to endpoint. Endpoint will be created if unspecified.</span>

<span class="sd">        Args:</span>
<span class="sd">            endpoint (&quot;Endpoint&quot;):</span>
<span class="sd">                Optional. Endpoint to deploy model to. If not specified, endpoint</span>
<span class="sd">                display name will be model display name+&#39;_endpoint&#39;.</span>
<span class="sd">            deployed_model_display_name (str):</span>
<span class="sd">                Optional. The display name of the DeployedModel. If not provided</span>
<span class="sd">                upon creation, the Model&#39;s display_name is used.</span>
<span class="sd">            traffic_percentage (int):</span>
<span class="sd">                Optional. Desired traffic to newly deployed model. Defaults to</span>
<span class="sd">                0 if there are pre-existing deployed models. Defaults to 100 if</span>
<span class="sd">                there are no pre-existing deployed models. Negative values should</span>
<span class="sd">                not be provided. Traffic of previously deployed models at the endpoint</span>
<span class="sd">                will be scaled down to accommodate new deployed model&#39;s traffic.</span>
<span class="sd">                Should not be provided if traffic_split is provided.</span>
<span class="sd">            traffic_split (Dict[str, int]):</span>
<span class="sd">                Optional. A map from a DeployedModel&#39;s ID to the percentage of</span>
<span class="sd">                this Endpoint&#39;s traffic that should be forwarded to that DeployedModel.</span>
<span class="sd">                If a DeployedModel&#39;s ID is not listed in this map, then it receives</span>
<span class="sd">                no traffic. The traffic percentage values must add up to 100, or</span>
<span class="sd">                map must be empty if the Endpoint is to not accept any traffic at</span>
<span class="sd">                the moment. Key for model being deployed is &quot;0&quot;. Should not be</span>
<span class="sd">                provided if traffic_percentage is provided.</span>
<span class="sd">            machine_type (str):</span>
<span class="sd">                Optional. The type of machine. Not specifying machine type will</span>
<span class="sd">                result in model to be deployed with automatic resources.</span>
<span class="sd">            min_replica_count (int):</span>
<span class="sd">                Optional. The minimum number of machine replicas this deployed</span>
<span class="sd">                model will be always deployed on. If traffic against it increases,</span>
<span class="sd">                it may dynamically be deployed onto more replicas, and as traffic</span>
<span class="sd">                decreases, some of these extra replicas may be freed.</span>
<span class="sd">            max_replica_count (int):</span>
<span class="sd">                Optional. The maximum number of replicas this deployed model may</span>
<span class="sd">                be deployed on when the traffic against it increases. If requested</span>
<span class="sd">                value is too large, the deployment will error, but if deployment</span>
<span class="sd">                succeeds then the ability to scale the model to that many replicas</span>
<span class="sd">                is guaranteed (barring service outages). If traffic against the</span>
<span class="sd">                deployed model increases beyond what its replicas at maximum may</span>
<span class="sd">                handle, a portion of the traffic will be dropped. If this value</span>
<span class="sd">                is not provided, the smaller value of min_replica_count or 1 will</span>
<span class="sd">                be used.</span>
<span class="sd">            accelerator_type (str):</span>
<span class="sd">                Optional. Hardware accelerator type. Must also set accelerator_count if used.</span>
<span class="sd">                One of ACCELERATOR_TYPE_UNSPECIFIED, NVIDIA_TESLA_K80, NVIDIA_TESLA_P100,</span>
<span class="sd">                NVIDIA_TESLA_V100, NVIDIA_TESLA_P4, NVIDIA_TESLA_T4</span>
<span class="sd">            accelerator_count (int):</span>
<span class="sd">                Optional. The number of accelerators to attach to a worker replica.</span>
<span class="sd">            service_account (str):</span>
<span class="sd">                The service account that the DeployedModel&#39;s container runs as. Specify the</span>
<span class="sd">                email address of the service account. If this service account is not</span>
<span class="sd">                specified, the container runs as a service account that doesn&#39;t have access</span>
<span class="sd">                to the resource project.</span>
<span class="sd">                Users deploying the Model must have the `iam.serviceAccounts.actAs`</span>
<span class="sd">                permission on this service account.</span>
<span class="sd">            explanation_metadata (explain.ExplanationMetadata):</span>
<span class="sd">                Optional. Metadata describing the Model&#39;s input and output for explanation.</span>
<span class="sd">                Both `explanation_metadata` and `explanation_parameters` must be</span>
<span class="sd">                passed together when used. For more details, see</span>
<span class="sd">                `Ref docs &lt;http://tinyurl.com/1igh60kt&gt;`</span>
<span class="sd">            explanation_parameters (explain.ExplanationParameters):</span>
<span class="sd">                Optional. Parameters to configure explaining for Model&#39;s predictions.</span>
<span class="sd">                For more details, see `Ref docs &lt;http://tinyurl.com/1an4zake&gt;`</span>
<span class="sd">            metadata (Sequence[Tuple[str, str]]):</span>
<span class="sd">                Optional. Strings which should be sent along with the request as</span>
<span class="sd">                metadata.</span>
<span class="sd">            encryption_spec_key_name (Optional[str]):</span>
<span class="sd">                Optional. The Cloud KMS resource identifier of the customer</span>
<span class="sd">                managed encryption key used to protect the model. Has the</span>
<span class="sd">                form:</span>
<span class="sd">                ``projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key``.</span>
<span class="sd">                The key needs to be in the same region as where the compute</span>
<span class="sd">                resource is created.</span>

<span class="sd">                If set, this Model and all sub-resources of this Model will be secured by this key.</span>

<span class="sd">                Overrides encryption_spec_key_name set in aiplatform.init</span>
<span class="sd">            sync (bool):</span>
<span class="sd">                Whether to execute this method synchronously. If False, this method</span>
<span class="sd">                will be executed in concurrent Future and any downstream object will</span>
<span class="sd">                be immediately returned and synced when the Future has completed.</span>
<span class="sd">        Returns:</span>
<span class="sd">            endpoint (&quot;Endpoint&quot;):</span>
<span class="sd">                Endpoint with the deployed model.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">Endpoint</span><span class="o">.</span><span class="n">_validate_deploy_args</span><span class="p">(</span>
            <span class="n">min_replica_count</span><span class="p">,</span>
            <span class="n">max_replica_count</span><span class="p">,</span>
            <span class="n">accelerator_type</span><span class="p">,</span>
            <span class="n">deployed_model_display_name</span><span class="p">,</span>
            <span class="n">traffic_split</span><span class="p">,</span>
            <span class="n">traffic_percentage</span><span class="p">,</span>
            <span class="n">explanation_metadata</span><span class="p">,</span>
            <span class="n">explanation_parameters</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_deploy</span><span class="p">(</span>
            <span class="n">endpoint</span><span class="o">=</span><span class="n">endpoint</span><span class="p">,</span>
            <span class="n">deployed_model_display_name</span><span class="o">=</span><span class="n">deployed_model_display_name</span><span class="p">,</span>
            <span class="n">traffic_percentage</span><span class="o">=</span><span class="n">traffic_percentage</span><span class="p">,</span>
            <span class="n">traffic_split</span><span class="o">=</span><span class="n">traffic_split</span><span class="p">,</span>
            <span class="n">machine_type</span><span class="o">=</span><span class="n">machine_type</span><span class="p">,</span>
            <span class="n">min_replica_count</span><span class="o">=</span><span class="n">min_replica_count</span><span class="p">,</span>
            <span class="n">max_replica_count</span><span class="o">=</span><span class="n">max_replica_count</span><span class="p">,</span>
            <span class="n">accelerator_type</span><span class="o">=</span><span class="n">accelerator_type</span><span class="p">,</span>
            <span class="n">accelerator_count</span><span class="o">=</span><span class="n">accelerator_count</span><span class="p">,</span>
            <span class="n">service_account</span><span class="o">=</span><span class="n">service_account</span><span class="p">,</span>
            <span class="n">explanation_metadata</span><span class="o">=</span><span class="n">explanation_metadata</span><span class="p">,</span>
            <span class="n">explanation_parameters</span><span class="o">=</span><span class="n">explanation_parameters</span><span class="p">,</span>
            <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
            <span class="n">encryption_spec_key_name</span><span class="o">=</span><span class="n">encryption_spec_key_name</span>
            <span class="ow">or</span> <span class="n">initializer</span><span class="o">.</span><span class="n">global_config</span><span class="o">.</span><span class="n">encryption_spec_key_name</span><span class="p">,</span>
            <span class="n">sync</span><span class="o">=</span><span class="n">sync</span><span class="p">,</span>
        <span class="p">)</span></div>

    <span class="nd">@base</span><span class="o">.</span><span class="n">optional_sync</span><span class="p">(</span><span class="n">return_input_arg</span><span class="o">=</span><span class="s2">&quot;endpoint&quot;</span><span class="p">,</span> <span class="n">bind_future_to_self</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_deploy</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">endpoint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;Endpoint&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">deployed_model_display_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">traffic_percentage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">traffic_split</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">machine_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">min_replica_count</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">max_replica_count</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">accelerator_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">accelerator_count</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">service_account</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">explanation_metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">explain</span><span class="o">.</span><span class="n">ExplanationMetadata</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">explanation_parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">explain</span><span class="o">.</span><span class="n">ExplanationParameters</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">(),</span>
        <span class="n">encryption_spec_key_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sync</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Endpoint</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Deploys model to endpoint. Endpoint will be created if unspecified.</span>

<span class="sd">        Args:</span>
<span class="sd">            endpoint (&quot;Endpoint&quot;):</span>
<span class="sd">                Optional. Endpoint to deploy model to. If not specified, endpoint</span>
<span class="sd">                display name will be model display name+&#39;_endpoint&#39;.</span>
<span class="sd">            deployed_model_display_name (str):</span>
<span class="sd">                Optional. The display name of the DeployedModel. If not provided</span>
<span class="sd">                upon creation, the Model&#39;s display_name is used.</span>
<span class="sd">            traffic_percentage (int):</span>
<span class="sd">                Optional. Desired traffic to newly deployed model. Defaults to</span>
<span class="sd">                0 if there are pre-existing deployed models. Defaults to 100 if</span>
<span class="sd">                there are no pre-existing deployed models. Negative values should</span>
<span class="sd">                not be provided. Traffic of previously deployed models at the endpoint</span>
<span class="sd">                will be scaled down to accommodate new deployed model&#39;s traffic.</span>
<span class="sd">                Should not be provided if traffic_split is provided.</span>
<span class="sd">            traffic_split (Dict[str, int]):</span>
<span class="sd">                Optional. A map from a DeployedModel&#39;s ID to the percentage of</span>
<span class="sd">                this Endpoint&#39;s traffic that should be forwarded to that DeployedModel.</span>
<span class="sd">                If a DeployedModel&#39;s ID is not listed in this map, then it receives</span>
<span class="sd">                no traffic. The traffic percentage values must add up to 100, or</span>
<span class="sd">                map must be empty if the Endpoint is to not accept any traffic at</span>
<span class="sd">                the moment. Key for model being deployed is &quot;0&quot;. Should not be</span>
<span class="sd">                provided if traffic_percentage is provided.</span>
<span class="sd">            machine_type (str):</span>
<span class="sd">                Optional. The type of machine. Not specifying machine type will</span>
<span class="sd">                result in model to be deployed with automatic resources.</span>
<span class="sd">            min_replica_count (int):</span>
<span class="sd">                Optional. The minimum number of machine replicas this deployed</span>
<span class="sd">                model will be always deployed on. If traffic against it increases,</span>
<span class="sd">                it may dynamically be deployed onto more replicas, and as traffic</span>
<span class="sd">                decreases, some of these extra replicas may be freed.</span>
<span class="sd">            max_replica_count (int):</span>
<span class="sd">                Optional. The maximum number of replicas this deployed model may</span>
<span class="sd">                be deployed on when the traffic against it increases. If requested</span>
<span class="sd">                value is too large, the deployment will error, but if deployment</span>
<span class="sd">                succeeds then the ability to scale the model to that many replicas</span>
<span class="sd">                is guaranteed (barring service outages). If traffic against the</span>
<span class="sd">                deployed model increases beyond what its replicas at maximum may</span>
<span class="sd">                handle, a portion of the traffic will be dropped. If this value</span>
<span class="sd">                is not provided, the smaller value of min_replica_count or 1 will</span>
<span class="sd">                be used.</span>
<span class="sd">            accelerator_type (str):</span>
<span class="sd">                Optional. Hardware accelerator type. Must also set accelerator_count if used.</span>
<span class="sd">                One of ACCELERATOR_TYPE_UNSPECIFIED, NVIDIA_TESLA_K80, NVIDIA_TESLA_P100,</span>
<span class="sd">                NVIDIA_TESLA_V100, NVIDIA_TESLA_P4, NVIDIA_TESLA_T4</span>
<span class="sd">            accelerator_count (int):</span>
<span class="sd">                Optional. The number of accelerators to attach to a worker replica.</span>
<span class="sd">            service_account (str):</span>
<span class="sd">                The service account that the DeployedModel&#39;s container runs as. Specify the</span>
<span class="sd">                email address of the service account. If this service account is not</span>
<span class="sd">                specified, the container runs as a service account that doesn&#39;t have access</span>
<span class="sd">                to the resource project.</span>
<span class="sd">                Users deploying the Model must have the `iam.serviceAccounts.actAs`</span>
<span class="sd">                permission on this service account.</span>
<span class="sd">            explanation_metadata (explain.ExplanationMetadata):</span>
<span class="sd">                Optional. Metadata describing the Model&#39;s input and output for explanation.</span>
<span class="sd">                Both `explanation_metadata` and `explanation_parameters` must be</span>
<span class="sd">                passed together when used. For more details, see</span>
<span class="sd">                `Ref docs &lt;http://tinyurl.com/1igh60kt&gt;`</span>
<span class="sd">            explanation_parameters (explain.ExplanationParameters):</span>
<span class="sd">                Optional. Parameters to configure explaining for Model&#39;s predictions.</span>
<span class="sd">                For more details, see `Ref docs &lt;http://tinyurl.com/1an4zake&gt;`</span>
<span class="sd">            metadata (Sequence[Tuple[str, str]]):</span>
<span class="sd">                Optional. Strings which should be sent along with the request as</span>
<span class="sd">                metadata.</span>
<span class="sd">            encryption_spec_key_name (Optional[str]):</span>
<span class="sd">                Optional. The Cloud KMS resource identifier of the customer</span>
<span class="sd">                managed encryption key used to protect the model. Has the</span>
<span class="sd">                form:</span>
<span class="sd">                ``projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key``.</span>
<span class="sd">                The key needs to be in the same region as where the compute</span>
<span class="sd">                resource is created.</span>

<span class="sd">                If set, this Model and all sub-resources of this Model will be secured by this key.</span>

<span class="sd">                Overrides encryption_spec_key_name set in aiplatform.init</span>
<span class="sd">            sync (bool):</span>
<span class="sd">                Whether to execute this method synchronously. If False, this method</span>
<span class="sd">                will be executed in concurrent Future and any downstream object will</span>
<span class="sd">                be immediately returned and synced when the Future has completed.</span>
<span class="sd">        Returns:</span>
<span class="sd">            endpoint (&quot;Endpoint&quot;):</span>
<span class="sd">                Endpoint with the deployed model.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">endpoint</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">display_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">display_name</span><span class="p">[:</span><span class="mi">118</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;_endpoint&quot;</span>
            <span class="n">endpoint</span> <span class="o">=</span> <span class="n">Endpoint</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
                <span class="n">display_name</span><span class="o">=</span><span class="n">display_name</span><span class="p">,</span>
                <span class="n">project</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">project</span><span class="p">,</span>
                <span class="n">location</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">location</span><span class="p">,</span>
                <span class="n">credentials</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">credentials</span><span class="p">,</span>
                <span class="n">encryption_spec_key_name</span><span class="o">=</span><span class="n">encryption_spec_key_name</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">log_action_start_against_resource</span><span class="p">(</span><span class="s2">&quot;Deploying model to&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">)</span>

        <span class="n">Endpoint</span><span class="o">.</span><span class="n">_deploy_call</span><span class="p">(</span>
            <span class="n">endpoint</span><span class="o">.</span><span class="n">api_client</span><span class="p">,</span>
            <span class="n">endpoint</span><span class="o">.</span><span class="n">resource_name</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resource_name</span><span class="p">,</span>
            <span class="n">endpoint</span><span class="o">.</span><span class="n">_gca_resource</span><span class="o">.</span><span class="n">traffic_split</span><span class="p">,</span>
            <span class="n">deployed_model_display_name</span><span class="o">=</span><span class="n">deployed_model_display_name</span><span class="p">,</span>
            <span class="n">traffic_percentage</span><span class="o">=</span><span class="n">traffic_percentage</span><span class="p">,</span>
            <span class="n">traffic_split</span><span class="o">=</span><span class="n">traffic_split</span><span class="p">,</span>
            <span class="n">machine_type</span><span class="o">=</span><span class="n">machine_type</span><span class="p">,</span>
            <span class="n">min_replica_count</span><span class="o">=</span><span class="n">min_replica_count</span><span class="p">,</span>
            <span class="n">max_replica_count</span><span class="o">=</span><span class="n">max_replica_count</span><span class="p">,</span>
            <span class="n">accelerator_type</span><span class="o">=</span><span class="n">accelerator_type</span><span class="p">,</span>
            <span class="n">accelerator_count</span><span class="o">=</span><span class="n">accelerator_count</span><span class="p">,</span>
            <span class="n">service_account</span><span class="o">=</span><span class="n">service_account</span><span class="p">,</span>
            <span class="n">explanation_metadata</span><span class="o">=</span><span class="n">explanation_metadata</span><span class="p">,</span>
            <span class="n">explanation_parameters</span><span class="o">=</span><span class="n">explanation_parameters</span><span class="p">,</span>
            <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">log_action_completed_against_resource</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="s2">&quot;deployed&quot;</span><span class="p">,</span> <span class="n">endpoint</span><span class="p">)</span>

        <span class="n">endpoint</span><span class="o">.</span><span class="n">_sync_gca_resource</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">endpoint</span>

<div class="viewcode-block" id="Model.batch_predict"><a class="viewcode-back" href="../../../../aiplatform.html#google.cloud.aiplatform.Model.batch_predict">[docs]</a>    <span class="k">def</span> <span class="nf">batch_predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">job_display_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">gcs_source</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">bigquery_source</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">instances_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;jsonl&quot;</span><span class="p">,</span>
        <span class="n">gcs_destination_prefix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">bigquery_destination_prefix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">predictions_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;jsonl&quot;</span><span class="p">,</span>
        <span class="n">model_parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">machine_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">accelerator_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">accelerator_count</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">starting_replica_count</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_replica_count</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">generate_explanation</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">explanation_metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">explain</span><span class="o">.</span><span class="n">ExplanationMetadata</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">explanation_parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">explain</span><span class="o">.</span><span class="n">ExplanationParameters</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">credentials</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">auth_credentials</span><span class="o">.</span><span class="n">Credentials</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">encryption_spec_key_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sync</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jobs</span><span class="o">.</span><span class="n">BatchPredictionJob</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Creates a batch prediction job using this Model and outputs</span>
<span class="sd">        prediction results to the provided destination prefix in the specified</span>
<span class="sd">        `predictions_format`. One source and one destination prefix are</span>
<span class="sd">        required.</span>

<span class="sd">        Example usage:</span>

<span class="sd">        my_model.batch_predict(</span>
<span class="sd">            job_display_name=&quot;prediction-123&quot;,</span>
<span class="sd">            gcs_source=&quot;gs://example-bucket/instances.csv&quot;,</span>
<span class="sd">            instances_format=&quot;csv&quot;,</span>
<span class="sd">            bigquery_destination_prefix=&quot;projectId.bqDatasetId.bqTableId&quot;</span>
<span class="sd">        )</span>

<span class="sd">        Args:</span>
<span class="sd">            job_display_name (str):</span>
<span class="sd">                Required. The user-defined name of the BatchPredictionJob.</span>
<span class="sd">                The name can be up to 128 characters long and can be consist</span>
<span class="sd">                of any UTF-8 characters.</span>
<span class="sd">            gcs_source: Optional[Sequence[str]] = None</span>
<span class="sd">                Google Cloud Storage URI(-s) to your instances to run</span>
<span class="sd">                batch prediction on. They must match `instances_format`.</span>
<span class="sd">                May contain wildcards. For more information on wildcards, see</span>
<span class="sd">                https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.</span>
<span class="sd">            bigquery_source: Optional[str] = None</span>
<span class="sd">                BigQuery URI to a table, up to 2000 characters long. For example:</span>
<span class="sd">                `projectId.bqDatasetId.bqTableId`</span>
<span class="sd">            instances_format: str = &quot;jsonl&quot;</span>
<span class="sd">                Required. The format in which instances are given, must be one</span>
<span class="sd">                of &quot;jsonl&quot;, &quot;csv&quot;, &quot;bigquery&quot;, &quot;tf-record&quot;, &quot;tf-record-gzip&quot;,</span>
<span class="sd">                or &quot;file-list&quot;. Default is &quot;jsonl&quot; when using `gcs_source`. If a</span>
<span class="sd">                `bigquery_source` is provided, this is overriden to &quot;bigquery&quot;.</span>
<span class="sd">            gcs_destination_prefix: Optional[str] = None</span>
<span class="sd">                The Google Cloud Storage location of the directory where the</span>
<span class="sd">                output is to be written to. In the given directory a new</span>
<span class="sd">                directory is created. Its name is</span>
<span class="sd">                ``prediction-&lt;model-display-name&gt;-&lt;job-create-time&gt;``, where</span>
<span class="sd">                timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format.</span>
<span class="sd">                Inside of it files ``predictions_0001.&lt;extension&gt;``,</span>
<span class="sd">                ``predictions_0002.&lt;extension&gt;``, ...,</span>
<span class="sd">                ``predictions_N.&lt;extension&gt;`` are created where</span>
<span class="sd">                ``&lt;extension&gt;`` depends on chosen ``predictions_format``,</span>
<span class="sd">                and N may equal 0001 and depends on the total number of</span>
<span class="sd">                successfully predicted instances. If the Model has both</span>
<span class="sd">                ``instance`` and ``prediction`` schemata defined then each such</span>
<span class="sd">                file contains predictions as per the ``predictions_format``.</span>
<span class="sd">                If prediction for any instance failed (partially or</span>
<span class="sd">                completely), then an additional ``errors_0001.&lt;extension&gt;``,</span>
<span class="sd">                ``errors_0002.&lt;extension&gt;``,..., ``errors_N.&lt;extension&gt;``</span>
<span class="sd">                files are created (N depends on total number of failed</span>
<span class="sd">                predictions). These files contain the failed instances, as</span>
<span class="sd">                per their schema, followed by an additional ``error`` field</span>
<span class="sd">                which as value has ```google.rpc.Status`` &lt;Status&gt;`__</span>
<span class="sd">                containing only ``code`` and ``message`` fields.</span>
<span class="sd">            bigquery_destination_prefix: Optional[str] = None</span>
<span class="sd">                The BigQuery project location where the output is to be</span>
<span class="sd">                written to. In the given project a new dataset is created</span>
<span class="sd">                with name</span>
<span class="sd">                ``prediction_&lt;model-display-name&gt;_&lt;job-create-time&gt;`` where</span>
<span class="sd">                is made BigQuery-dataset-name compatible (for example, most</span>
<span class="sd">                special characters become underscores), and timestamp is in</span>
<span class="sd">                YYYY_MM_DDThh_mm_ss_sssZ &quot;based on ISO-8601&quot; format. In the</span>
<span class="sd">                dataset two tables will be created, ``predictions``, and</span>
<span class="sd">                ``errors``. If the Model has both ``instance`` and ``prediction``</span>
<span class="sd">                schemata defined then the tables have columns as follows:</span>
<span class="sd">                The ``predictions`` table contains instances for which the</span>
<span class="sd">                prediction succeeded, it has columns as per a concatenation</span>
<span class="sd">                of the Model&#39;s instance and prediction schemata. The</span>
<span class="sd">                ``errors`` table contains rows for which the prediction has</span>
<span class="sd">                failed, it has instance columns, as per the instance schema,</span>
<span class="sd">                followed by a single &quot;errors&quot; column, which as values has</span>
<span class="sd">                ```google.rpc.Status`` &lt;Status&gt;`__ represented as a STRUCT,</span>
<span class="sd">                and containing only ``code`` and ``message``.</span>
<span class="sd">            predictions_format: str = &quot;jsonl&quot;</span>
<span class="sd">                Required. The format in which Vertex AI gives the</span>
<span class="sd">                predictions, must be one of &quot;jsonl&quot;, &quot;csv&quot;, or &quot;bigquery&quot;.</span>
<span class="sd">                Default is &quot;jsonl&quot; when using `gcs_destination_prefix`. If a</span>
<span class="sd">                `bigquery_destination_prefix` is provided, this is overriden to</span>
<span class="sd">                &quot;bigquery&quot;.</span>
<span class="sd">            model_parameters: Optional[Dict] = None</span>
<span class="sd">                Optional. The parameters that govern the predictions. The schema of</span>
<span class="sd">                the parameters may be specified via the Model&#39;s `parameters_schema_uri`.</span>
<span class="sd">            machine_type: Optional[str] = None</span>
<span class="sd">                Optional. The type of machine for running batch prediction on</span>
<span class="sd">                dedicated resources. Not specifying machine type will result in</span>
<span class="sd">                batch prediction job being run with automatic resources.</span>
<span class="sd">            accelerator_type: Optional[str] = None</span>
<span class="sd">                Optional. The type of accelerator(s) that may be attached</span>
<span class="sd">                to the machine as per `accelerator_count`. Only used if</span>
<span class="sd">                `machine_type` is set.</span>
<span class="sd">            accelerator_count: Optional[int] = None</span>
<span class="sd">                Optional. The number of accelerators to attach to the</span>
<span class="sd">                `machine_type`. Only used if `machine_type` is set.</span>
<span class="sd">            starting_replica_count: Optional[int] = None</span>
<span class="sd">                The number of machine replicas used at the start of the batch</span>
<span class="sd">                operation. If not set, Vertex AI decides starting number, not</span>
<span class="sd">                greater than `max_replica_count`. Only used if `machine_type` is</span>
<span class="sd">                set.</span>
<span class="sd">            max_replica_count: Optional[int] = None</span>
<span class="sd">                The maximum number of machine replicas the batch operation may</span>
<span class="sd">                be scaled to. Only used if `machine_type` is set.</span>
<span class="sd">                Default is 10.</span>
<span class="sd">            generate_explanation (bool):</span>
<span class="sd">                Optional. Generate explanation along with the batch prediction</span>
<span class="sd">                results. This will cause the batch prediction output to include</span>
<span class="sd">                explanations based on the `prediction_format`:</span>
<span class="sd">                    - `bigquery`: output includes a column named `explanation`. The value</span>
<span class="sd">                        is a struct that conforms to the [aiplatform.gapic.Explanation] object.</span>
<span class="sd">                    - `jsonl`: The JSON objects on each line include an additional entry</span>
<span class="sd">                        keyed `explanation`. The value of the entry is a JSON object that</span>
<span class="sd">                        conforms to the [aiplatform.gapic.Explanation] object.</span>
<span class="sd">                    - `csv`: Generating explanations for CSV format is not supported.</span>
<span class="sd">            explanation_metadata (explain.ExplanationMetadata):</span>
<span class="sd">                Optional. Explanation metadata configuration for this BatchPredictionJob.</span>
<span class="sd">                Can be specified only if `generate_explanation` is set to `True`.</span>

<span class="sd">                This value overrides the value of `Model.explanation_metadata`.</span>
<span class="sd">                All fields of `explanation_metadata` are optional in the request. If</span>
<span class="sd">                a field of the `explanation_metadata` object is not populated, the</span>
<span class="sd">                corresponding field of the `Model.explanation_metadata` object is inherited.</span>
<span class="sd">                For more details, see `Ref docs &lt;http://tinyurl.com/1igh60kt&gt;`</span>
<span class="sd">            explanation_parameters (explain.ExplanationParameters):</span>
<span class="sd">                Optional. Parameters to configure explaining for Model&#39;s predictions.</span>
<span class="sd">                Can be specified only if `generate_explanation` is set to `True`.</span>

<span class="sd">                This value overrides the value of `Model.explanation_parameters`.</span>
<span class="sd">                All fields of `explanation_parameters` are optional in the request. If</span>
<span class="sd">                a field of the `explanation_parameters` object is not populated, the</span>
<span class="sd">                corresponding field of the `Model.explanation_parameters` object is inherited.</span>
<span class="sd">                For more details, see `Ref docs &lt;http://tinyurl.com/1an4zake&gt;`</span>
<span class="sd">            labels: Optional[dict] = None</span>
<span class="sd">                Optional. The labels with user-defined metadata to organize your</span>
<span class="sd">                BatchPredictionJobs. Label keys and values can be no longer than</span>
<span class="sd">                64 characters (Unicode codepoints), can only contain lowercase</span>
<span class="sd">                letters, numeric characters, underscores and dashes.</span>
<span class="sd">                International characters are allowed. See https://goo.gl/xmQnxf</span>
<span class="sd">                for more information and examples of labels.</span>
<span class="sd">            credentials: Optional[auth_credentials.Credentials] = None</span>
<span class="sd">                Optional. Custom credentials to use to create this batch prediction</span>
<span class="sd">                job. Overrides credentials set in aiplatform.init.</span>
<span class="sd">            encryption_spec_key_name (Optional[str]):</span>
<span class="sd">                Optional. The Cloud KMS resource identifier of the customer</span>
<span class="sd">                managed encryption key used to protect the model. Has the</span>
<span class="sd">                form:</span>
<span class="sd">                ``projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key``.</span>
<span class="sd">                The key needs to be in the same region as where the compute</span>
<span class="sd">                resource is created.</span>

<span class="sd">                If set, this Model and all sub-resources of this Model will be secured by this key.</span>

<span class="sd">                Overrides encryption_spec_key_name set in aiplatform.init.</span>
<span class="sd">        Returns:</span>
<span class="sd">            (jobs.BatchPredictionJob):</span>
<span class="sd">                Instantiated representation of the created batch prediction job.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">jobs</span><span class="o">.</span><span class="n">BatchPredictionJob</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">job_display_name</span><span class="o">=</span><span class="n">job_display_name</span><span class="p">,</span>
            <span class="n">model_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">resource_name</span><span class="p">,</span>
            <span class="n">instances_format</span><span class="o">=</span><span class="n">instances_format</span><span class="p">,</span>
            <span class="n">predictions_format</span><span class="o">=</span><span class="n">predictions_format</span><span class="p">,</span>
            <span class="n">gcs_source</span><span class="o">=</span><span class="n">gcs_source</span><span class="p">,</span>
            <span class="n">bigquery_source</span><span class="o">=</span><span class="n">bigquery_source</span><span class="p">,</span>
            <span class="n">gcs_destination_prefix</span><span class="o">=</span><span class="n">gcs_destination_prefix</span><span class="p">,</span>
            <span class="n">bigquery_destination_prefix</span><span class="o">=</span><span class="n">bigquery_destination_prefix</span><span class="p">,</span>
            <span class="n">model_parameters</span><span class="o">=</span><span class="n">model_parameters</span><span class="p">,</span>
            <span class="n">machine_type</span><span class="o">=</span><span class="n">machine_type</span><span class="p">,</span>
            <span class="n">accelerator_type</span><span class="o">=</span><span class="n">accelerator_type</span><span class="p">,</span>
            <span class="n">accelerator_count</span><span class="o">=</span><span class="n">accelerator_count</span><span class="p">,</span>
            <span class="n">starting_replica_count</span><span class="o">=</span><span class="n">starting_replica_count</span><span class="p">,</span>
            <span class="n">max_replica_count</span><span class="o">=</span><span class="n">max_replica_count</span><span class="p">,</span>
            <span class="n">generate_explanation</span><span class="o">=</span><span class="n">generate_explanation</span><span class="p">,</span>
            <span class="n">explanation_metadata</span><span class="o">=</span><span class="n">explanation_metadata</span><span class="p">,</span>
            <span class="n">explanation_parameters</span><span class="o">=</span><span class="n">explanation_parameters</span><span class="p">,</span>
            <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
            <span class="n">project</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">project</span><span class="p">,</span>
            <span class="n">location</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">location</span><span class="p">,</span>
            <span class="n">credentials</span><span class="o">=</span><span class="n">credentials</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">credentials</span><span class="p">,</span>
            <span class="n">encryption_spec_key_name</span><span class="o">=</span><span class="n">encryption_spec_key_name</span><span class="p">,</span>
            <span class="n">sync</span><span class="o">=</span><span class="n">sync</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Model.list"><a class="viewcode-back" href="../../../../aiplatform.html#google.cloud.aiplatform.Model.list">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">list</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="nb">filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">order_by</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">project</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">location</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">credentials</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">auth_credentials</span><span class="o">.</span><span class="n">Credentials</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;models.Model&quot;</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;List all Model resource instances.</span>

<span class="sd">        Example Usage:</span>

<span class="sd">        aiplatform.Model.list(</span>
<span class="sd">            filter=&#39;labels.my_label=&quot;my_label_value&quot; AND display_name=&quot;my_model&quot;&#39;,</span>
<span class="sd">        )</span>

<span class="sd">        Args:</span>
<span class="sd">            filter (str):</span>
<span class="sd">                Optional. An expression for filtering the results of the request.</span>
<span class="sd">                For field names both snake_case and camelCase are supported.</span>
<span class="sd">            order_by (str):</span>
<span class="sd">                Optional. A comma-separated list of fields to order by, sorted in</span>
<span class="sd">                ascending order. Use &quot;desc&quot; after a field name for descending.</span>
<span class="sd">                Supported fields: `display_name`, `create_time`, `update_time`</span>
<span class="sd">            project (str):</span>
<span class="sd">                Optional. Project to retrieve list from. If not set, project</span>
<span class="sd">                set in aiplatform.init will be used.</span>
<span class="sd">            location (str):</span>
<span class="sd">                Optional. Location to retrieve list from. If not set, location</span>
<span class="sd">                set in aiplatform.init will be used.</span>
<span class="sd">            credentials (auth_credentials.Credentials):</span>
<span class="sd">                Optional. Custom credentials to use to retrieve list. Overrides</span>
<span class="sd">                credentials set in aiplatform.init.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[models.Model] - A list of Model resource objects</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_list</span><span class="p">(</span>
            <span class="nb">filter</span><span class="o">=</span><span class="nb">filter</span><span class="p">,</span>
            <span class="n">order_by</span><span class="o">=</span><span class="n">order_by</span><span class="p">,</span>
            <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span>
            <span class="n">location</span><span class="o">=</span><span class="n">location</span><span class="p">,</span>
            <span class="n">credentials</span><span class="o">=</span><span class="n">credentials</span><span class="p">,</span>
        <span class="p">)</span></div>

    <span class="nd">@base</span><span class="o">.</span><span class="n">optional_sync</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">_wait_on_export</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">operation_future</span><span class="p">:</span> <span class="n">operation</span><span class="o">.</span><span class="n">Operation</span><span class="p">,</span> <span class="n">sync</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">operation_future</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>

<div class="viewcode-block" id="Model.export_model"><a class="viewcode-back" href="../../../../aiplatform.html#google.cloud.aiplatform.Model.export_model">[docs]</a>    <span class="k">def</span> <span class="nf">export_model</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">export_format_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">artifact_destination</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">image_destination</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sync</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Exports a trained, exportable Model to a location specified by the user.</span>
<span class="sd">        A Model is considered to be exportable if it has at least one `supported_export_formats`.</span>
<span class="sd">        Either `artifact_destination` or `image_destination` must be provided.</span>

<span class="sd">        Usage:</span>
<span class="sd">            my_model.export(</span>
<span class="sd">                export_format_id=&#39;tf-saved-model&#39;</span>
<span class="sd">                artifact_destination=&#39;gs://my-bucket/models/&#39;</span>
<span class="sd">            )</span>

<span class="sd">            or</span>

<span class="sd">            my_model.export(</span>
<span class="sd">                export_format_id=&#39;custom-model&#39;</span>
<span class="sd">                image_destination=&#39;us-central1-docker.pkg.dev/projectId/repo/image&#39;</span>
<span class="sd">            )</span>

<span class="sd">        Args:</span>
<span class="sd">            export_format_id (str):</span>
<span class="sd">                Required. The ID of the format in which the Model must be exported.</span>
<span class="sd">                The list of export formats that this Model supports can be found</span>
<span class="sd">                by calling `Model.supported_export_formats`.</span>
<span class="sd">            artifact_destination (str):</span>
<span class="sd">                The Cloud Storage location where the Model artifact is to be</span>
<span class="sd">                written to. Under the directory given as the destination a</span>
<span class="sd">                new one with name</span>
<span class="sd">                &quot;``model-export-&lt;model-display-name&gt;-&lt;timestamp-of-export-call&gt;``&quot;,</span>
<span class="sd">                where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601</span>
<span class="sd">                format, will be created. Inside, the Model and any of its</span>
<span class="sd">                supporting files will be written.</span>

<span class="sd">                This field should only be set when, in [Model.supported_export_formats],</span>
<span class="sd">                the value for the key given in `export_format_id` contains ``ARTIFACT``.</span>
<span class="sd">            image_destination (str):</span>
<span class="sd">                The Google Container Registry or Artifact Registry URI where</span>
<span class="sd">                the Model container image will be copied to. Accepted forms:</span>

<span class="sd">                -  Google Container Registry path. For example:</span>
<span class="sd">                ``gcr.io/projectId/imageName:tag``.</span>

<span class="sd">                -  Artifact Registry path. For example:</span>
<span class="sd">                ``us-central1-docker.pkg.dev/projectId/repoName/imageName:tag``.</span>

<span class="sd">                This field should only be set when, in [Model.supported_export_formats],</span>
<span class="sd">                the value for the key given in `export_format_id` contains ``IMAGE``.</span>
<span class="sd">            sync (bool):</span>
<span class="sd">                Whether to execute this export synchronously. If False, this method</span>
<span class="sd">                will be executed in concurrent Future and any downstream object will</span>
<span class="sd">                be immediately returned and synced when the Future has completed.</span>
<span class="sd">        Returns:</span>
<span class="sd">            output_info (Dict[str, str]):</span>
<span class="sd">                Details of the completed export with output destination paths to</span>
<span class="sd">                the artifacts or container image.</span>
<span class="sd">        Raises:</span>
<span class="sd">            ValueError if model does not support exporting.</span>

<span class="sd">            ValueError if invalid arguments or export formats are provided.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Model does not support exporting</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">supported_export_formats</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The model `</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">resource_name</span><span class="si">}</span><span class="s2">` is not exportable.&quot;</span><span class="p">)</span>

        <span class="c1"># No destination provided</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">((</span><span class="n">artifact_destination</span><span class="p">,</span> <span class="n">image_destination</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Please provide an `artifact_destination` or `image_destination`.&quot;</span>
            <span class="p">)</span>

        <span class="n">export_format_id</span> <span class="o">=</span> <span class="n">export_format_id</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

        <span class="c1"># Unsupported export type</span>
        <span class="k">if</span> <span class="n">export_format_id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">supported_export_formats</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">export_format_id</span><span class="si">}</span><span class="s2">&#39; is not a supported export format for this model. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Choose one of the following: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">supported_export_formats</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">content_types</span> <span class="o">=</span> <span class="n">gca_model_compat</span><span class="o">.</span><span class="n">Model</span><span class="o">.</span><span class="n">ExportFormat</span><span class="o">.</span><span class="n">ExportableContent</span>
        <span class="n">supported_content_types</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">supported_export_formats</span><span class="p">[</span><span class="n">export_format_id</span><span class="p">]</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="n">artifact_destination</span>
            <span class="ow">and</span> <span class="n">content_types</span><span class="o">.</span><span class="n">ARTIFACT</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">supported_content_types</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;This model can not be exported as an artifact in &#39;</span><span class="si">{export_format_id}</span><span class="s2">&#39; format. &quot;</span>
                <span class="s2">&quot;Try exporting as a container image by passing the `image_destination` argument.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">image_destination</span> <span class="ow">and</span> <span class="n">content_types</span><span class="o">.</span><span class="n">IMAGE</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">supported_content_types</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;This model can not be exported as a container image in &#39;</span><span class="si">{export_format_id}</span><span class="s2">&#39; format. &quot;</span>
                <span class="s2">&quot;Try exporting the model artifacts by passing a `artifact_destination` argument.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Construct request payload</span>
        <span class="n">output_config</span> <span class="o">=</span> <span class="n">gca_model_service_compat</span><span class="o">.</span><span class="n">ExportModelRequest</span><span class="o">.</span><span class="n">OutputConfig</span><span class="p">(</span>
            <span class="n">export_format_id</span><span class="o">=</span><span class="n">export_format_id</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">artifact_destination</span><span class="p">:</span>
            <span class="n">output_config</span><span class="o">.</span><span class="n">artifact_destination</span> <span class="o">=</span> <span class="n">gca_io_compat</span><span class="o">.</span><span class="n">GcsDestination</span><span class="p">(</span>
                <span class="n">output_uri_prefix</span><span class="o">=</span><span class="n">artifact_destination</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">image_destination</span><span class="p">:</span>
            <span class="n">output_config</span><span class="o">.</span><span class="n">image_destination</span> <span class="o">=</span> <span class="n">gca_io_compat</span><span class="o">.</span><span class="n">ContainerRegistryDestination</span><span class="p">(</span>
                <span class="n">output_uri</span><span class="o">=</span><span class="n">image_destination</span>
            <span class="p">)</span>

        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">log_action_start_against_resource</span><span class="p">(</span><span class="s2">&quot;Exporting&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

        <span class="n">operation_future</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">api_client</span><span class="o">.</span><span class="n">export_model</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">resource_name</span><span class="p">,</span> <span class="n">output_config</span><span class="o">=</span><span class="n">output_config</span>
        <span class="p">)</span>

        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">log_action_started_against_resource_with_lro</span><span class="p">(</span>
            <span class="s2">&quot;Export&quot;</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">,</span> <span class="n">operation_future</span>
        <span class="p">)</span>

        <span class="c1"># Block before returning</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_wait_on_export</span><span class="p">(</span><span class="n">operation_future</span><span class="o">=</span><span class="n">operation_future</span><span class="p">,</span> <span class="n">sync</span><span class="o">=</span><span class="n">sync</span><span class="p">)</span>

        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">log_action_completed_against_resource</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="s2">&quot;exported&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">json_format</span><span class="o">.</span><span class="n">MessageToDict</span><span class="p">(</span><span class="n">operation_future</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">output_info</span><span class="o">.</span><span class="n">_pb</span><span class="p">)</span></div></div>
</pre></div>

          </div>
          
      </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2019, Google.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>